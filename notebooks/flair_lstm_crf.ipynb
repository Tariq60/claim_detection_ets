{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence, Corpus\n",
    "from flair.datasets import UD_ENGLISH, ColumnCorpus\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedding = TransformerWordEmbeddings('bert-base-cased')\n",
    "sentence = Sentence('The grass is green .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\n",
      "tensor([ 0.2881, -0.6816,  0.5577,  ...,  0.8676,  0.0792,  0.8672])\n",
      "Token: 2 grass\n",
      "tensor([-0.0703, -0.0699,  0.0544,  ..., -0.2776, -1.0295, -0.3793])\n",
      "Token: 3 is\n",
      "tensor([ 0.0810, -0.3258,  0.4203,  ...,  0.2182,  0.3702,  0.9412])\n",
      "Token: 4 green\n",
      "tensor([ 0.0508, -0.4786,  0.3054,  ..., -0.6855, -0.0248,  0.6028])\n",
      "Token: 5 .\n",
      "tensor([ 0.6098, -0.1838, -0.0825,  ...,  0.2716, -0.0733,  0.3918])\n"
     ]
    }
   ],
   "source": [
    "bert_embedding.embed(sentence)\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 This\n",
      "tensor([ 0.4386, -0.5114,  0.6741,  ...,  1.2735, -0.1206,  0.6134])\n",
      "Token: 2 is\n",
      "tensor([ 0.3237, -0.2456,  0.4793,  ...,  0.3411,  0.1160,  1.2343])\n",
      "Token: 3 the\n",
      "tensor([-0.0832, -0.4757, -0.0042,  ...,  0.9476,  0.2747,  1.3109])\n",
      "Token: 4 grass\n",
      "tensor([-0.1270,  0.0168,  0.0254,  ..., -0.1931, -0.7082,  0.3254])\n",
      "Token: 5 green\n",
      "tensor([ 0.0683, -0.2390,  0.5181,  ..., -0.5370, -1.0446,  0.7060])\n",
      "Token: 6 .\n",
      "tensor([ 0.2875, -0.0406,  0.1617,  ...,  1.1258,  0.0067,  0.4776])\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('This is the grass green .')\n",
    "bert_embedding.embed(sentence)\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 Where\n",
      "tensor([ 0.5379, -0.8622,  0.0541,  ..., -0.2395, -1.8098, -0.9114])\n",
      "Token: 2 did\n",
      "tensor([ 0.2666, -0.4282, -0.4665,  ...,  1.4636, -1.7452,  1.0283])\n",
      "Token: 3 you\n",
      "tensor([ 0.8508, -0.2540, -0.0265,  ...,  0.7896, -1.5016,  0.5311])\n",
      "Token: 4 put\n",
      "tensor([ 0.3347, -0.0850, -0.6118,  ...,  0.8824, -0.6401,  0.7491])\n",
      "Token: 5 the\n",
      "tensor([ 0.1939, -0.4221, -0.2043,  ...,  0.9627,  0.0954,  1.2726])\n",
      "Token: 6 grass\n",
      "tensor([ 0.0489,  0.0358,  0.0538,  ..., -0.6686, -0.9376, -0.3929])\n",
      "Token: 7 green\n",
      "tensor([ 0.2135, -0.1704,  0.3763,  ..., -0.4998, -0.2303,  0.5111])\n",
      "Token: 8 ?\n",
      "tensor([ 0.4633, -0.5424, -0.0246,  ...,  0.1583, -1.2093,  1.3458])\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('Where did you put the grass green ?')\n",
    "bert_embedding.embed(sentence)\n",
    "gensim\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-19 13:30:02,113 Reading data from /Users/talhindi/Documents/data_wm/merged_arg\n",
      "2020-08-19 13:30:02,114 Train: /Users/talhindi/Documents/data_wm/merged_arg/train.txt\n",
      "2020-08-19 13:30:02,114 Dev: /Users/talhindi/Documents/data_wm/merged_arg/dev.txt\n",
      "2020-08-19 13:30:02,115 Test: /Users/talhindi/Documents/data_wm/merged_arg/test.txt\n",
      "Corpus: 1862 train + 1266 dev + 1266 test sentences\n",
      "Dictionary with 7 tags: <unk>, O, O-claim, B-claim, I-claim, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# define columns\n",
    "columns = {0: 'text', 1: 'arg'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = '/Users/talhindi/Documents/data_wm/merged_arg/'\n",
    "\n",
    "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='dev.txt')\n",
    "print(corpus)\n",
    "\n",
    "tag_type = 'arg'\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. initialize embeddings\n",
    "# embedding_types = [\n",
    "\n",
    "#     WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    # FlairEmbeddings('news-backward'),\n",
    "# ]\n",
    "\n",
    "# embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=TransformerWordEmbeddings('bert-base-cased'),\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "# 6. initialize trainer\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. start training\n",
    "trainer.train('resources/taggers/example-pos',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
