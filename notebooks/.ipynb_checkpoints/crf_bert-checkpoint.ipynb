{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "# from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb1 = np.load('../features/train_claim_emb_0-2479.bert.npy', allow_pickle=True)\n",
    "train_emb2 = np.load('../features/train_claim_emb_2480-3772.bert.npy', allow_pickle=True)\n",
    "train_emb3 = np.load('../features/train_claim_emb_3773-end.bert.npy', allow_pickle=True)\n",
    "train_emb = list(train_emb1) + list(train_emb2) + list(train_emb3)\n",
    "\n",
    "test_emb = np.load('../features/test_claim_emb.bert.npy', allow_pickle=True)\n",
    "test_emb = list(test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 25\n",
      "3 29\n",
      "5 11\n",
      "7 27\n",
      "13 39\n",
      "16 35\n",
      "17 3\n",
      "19 11\n",
      "22 0\n",
      "22 4\n",
      "22 19\n",
      "23 14\n",
      "25 1\n",
      "25 9\n",
      "26 13\n",
      "27 0\n",
      "27 8\n",
      "29 18\n",
      "30 0\n",
      "30 4\n",
      "32 9\n",
      "32 11\n",
      "35 18\n",
      "36 19\n",
      "37 0\n",
      "37 11\n",
      "38 14\n",
      "38 24\n",
      "41 0\n",
      "42 15\n",
      "44 8\n",
      "51 0\n",
      "53 0\n",
      "60 21\n",
      "61 14\n",
      "62 7\n",
      "63 11\n",
      "67 21\n",
      "67 23\n",
      "67 33\n",
      "69 16\n",
      "70 0\n",
      "70 23\n",
      "71 18\n",
      "71 22\n",
      "71 24\n",
      "71 27\n",
      "73 1\n",
      "73 17\n",
      "73 24\n",
      "74 19\n",
      "75 7\n",
      "76 0\n",
      "76 13\n",
      "76 17\n",
      "78 0\n",
      "78 14\n",
      "78 17\n",
      "80 10\n",
      "81 9\n",
      "82 0\n",
      "85 8\n",
      "85 24\n",
      "86 8\n",
      "89 10\n",
      "91 12\n",
      "92 12\n",
      "95 0\n",
      "101 4\n",
      "101 18\n",
      "105 8\n",
      "105 17\n",
      "108 12\n",
      "109 5\n",
      "109 13\n",
      "110 11\n",
      "113 21\n",
      "115 5\n",
      "120 29\n",
      "122 7\n",
      "122 11\n",
      "122 12\n",
      "122 14\n",
      "122 15\n",
      "123 4\n",
      "123 7\n",
      "127 7\n",
      "128 7\n",
      "129 0\n",
      "129 22\n",
      "129 27\n",
      "132 12\n",
      "139 18\n",
      "140 10\n",
      "142 20\n",
      "148 13\n",
      "149 0\n",
      "149 10\n",
      "150 23\n",
      "151 8\n",
      "151 11\n",
      "152 3\n",
      "152 16\n",
      "155 1\n",
      "155 3\n",
      "156 1\n",
      "156 3\n",
      "158 32\n",
      "160 2\n",
      "161 3\n",
      "162 20\n",
      "166 6\n",
      "167 5\n",
      "172 13\n",
      "173 0\n",
      "178 0\n",
      "179 12\n",
      "180 5\n",
      "181 2\n",
      "188 33\n",
      "189 8\n",
      "189 15\n",
      "191 3\n",
      "192 7\n",
      "194 0\n",
      "196 7\n",
      "197 0\n",
      "197 3\n",
      "198 6\n",
      "201 19\n",
      "203 9\n",
      "206 11\n",
      "208 6\n",
      "208 19\n",
      "209 4\n",
      "209 9\n",
      "211 11\n",
      "212 7\n",
      "214 13\n",
      "216 18\n",
      "218 10\n",
      "220 5\n",
      "221 13\n",
      "223 6\n",
      "223 16\n",
      "223 24\n",
      "224 13\n",
      "226 9\n",
      "227 5\n",
      "227 11\n",
      "227 23\n",
      "227 25\n",
      "228 3\n",
      "232 7\n",
      "234 0\n",
      "241 10\n",
      "241 21\n",
      "243 5\n",
      "251 0\n",
      "254 2\n",
      "255 9\n",
      "258 6\n",
      "259 7\n",
      "264 12\n",
      "266 6\n",
      "273 19\n",
      "275 17\n",
      "285 7\n",
      "286 4\n",
      "288 20\n",
      "290 4\n",
      "290 19\n",
      "292 21\n",
      "294 12\n",
      "299 0\n",
      "299 10\n",
      "301 8\n",
      "301 9\n",
      "304 8\n",
      "305 39\n",
      "305 41\n",
      "310 4\n",
      "310 12\n",
      "311 19\n",
      "311 28\n",
      "312 4\n",
      "312 14\n",
      "313 33\n",
      "315 7\n",
      "315 9\n",
      "319 20\n",
      "320 26\n",
      "323 5\n",
      "323 24\n",
      "324 1\n",
      "328 8\n",
      "328 9\n",
      "328 13\n",
      "330 6\n",
      "331 14\n",
      "331 19\n",
      "332 18\n",
      "335 10\n",
      "336 26\n",
      "338 11\n",
      "339 24\n",
      "341 21\n",
      "343 6\n",
      "345 0\n",
      "348 13\n",
      "348 15\n",
      "352 8\n",
      "354 13\n",
      "354 22\n",
      "355 22\n",
      "357 6\n",
      "358 6\n",
      "359 11\n",
      "360 3\n",
      "360 4\n",
      "360 10\n",
      "361 0\n",
      "363 26\n",
      "363 28\n",
      "368 14\n",
      "374 17\n",
      "376 10\n",
      "377 0\n",
      "377 8\n",
      "379 16\n",
      "382 0\n",
      "384 27\n",
      "393 7\n",
      "400 0\n",
      "403 16\n",
      "405 13\n",
      "406 6\n",
      "406 14\n",
      "409 0\n",
      "412 0\n",
      "415 0\n",
      "415 12\n",
      "417 9\n",
      "418 11\n",
      "419 0\n",
      "423 16\n",
      "424 2\n",
      "424 3\n",
      "424 15\n",
      "425 12\n",
      "425 13\n",
      "429 7\n",
      "441 0\n",
      "442 5\n",
      "442 19\n",
      "443 16\n",
      "444 0\n",
      "446 6\n",
      "449 9\n",
      "449 12\n",
      "449 14\n",
      "452 2\n",
      "452 5\n",
      "452 8\n",
      "456 36\n",
      "457 3\n",
      "458 15\n",
      "460 8\n",
      "461 14\n",
      "462 5\n",
      "462 12\n",
      "463 20\n",
      "465 0\n",
      "466 10\n",
      "466 20\n",
      "467 8\n",
      "468 0\n",
      "468 2\n",
      "468 8\n",
      "469 5\n",
      "470 21\n",
      "470 24\n",
      "472 1\n",
      "473 15\n",
      "474 5\n",
      "474 25\n",
      "475 9\n",
      "476 2\n",
      "477 0\n",
      "478 3\n",
      "479 5\n",
      "480 6\n",
      "480 14\n",
      "480 24\n",
      "481 6\n",
      "482 0\n",
      "482 1\n",
      "483 6\n",
      "483 23\n",
      "484 3\n",
      "484 5\n",
      "484 9\n",
      "484 33\n",
      "485 6\n",
      "485 10\n",
      "485 12\n",
      "486 15\n",
      "490 0\n",
      "494 8\n",
      "495 5\n",
      "497 5\n",
      "501 17\n",
      "503 24\n",
      "513 19\n",
      "515 9\n",
      "518 5\n",
      "529 0\n",
      "531 11\n",
      "531 22\n",
      "533 0\n",
      "535 9\n",
      "535 11\n",
      "539 8\n",
      "545 12\n",
      "548 1\n",
      "549 2\n",
      "553 7\n",
      "556 0\n",
      "558 8\n",
      "558 9\n",
      "563 0\n",
      "565 7\n",
      "567 14\n",
      "568 0\n",
      "568 14\n",
      "569 12\n",
      "573 0\n",
      "576 10\n",
      "577 15\n",
      "579 13\n",
      "581 20\n",
      "583 0\n",
      "587 0\n",
      "591 1\n",
      "592 0\n",
      "593 2\n",
      "593 8\n",
      "596 0\n",
      "598 6\n",
      "598 20\n",
      "598 23\n",
      "601 4\n",
      "605 0\n",
      "607 7\n",
      "608 0\n",
      "611 7\n",
      "615 0\n",
      "618 7\n",
      "619 3\n",
      "622 7\n",
      "623 20\n",
      "625 10\n",
      "626 44\n",
      "627 2\n",
      "628 8\n",
      "628 27\n",
      "630 5\n",
      "631 0\n",
      "631 17\n",
      "632 4\n",
      "632 24\n",
      "633 26\n",
      "635 0\n",
      "636 19\n",
      "636 21\n",
      "640 4\n",
      "640 44\n",
      "641 13\n",
      "643 6\n",
      "644 19\n",
      "646 0\n",
      "651 7\n",
      "652 0\n",
      "653 8\n",
      "653 13\n",
      "654 15\n",
      "655 8\n",
      "657 4\n",
      "658 10\n",
      "659 12\n",
      "662 0\n",
      "662 16\n",
      "664 20\n",
      "668 12\n",
      "669 14\n",
      "670 18\n",
      "670 41\n",
      "675 11\n",
      "677 19\n",
      "677 34\n",
      "682 24\n",
      "683 0\n",
      "683 8\n",
      "683 12\n",
      "683 56\n",
      "684 12\n",
      "690 3\n",
      "691 6\n",
      "692 10\n",
      "693 4\n",
      "693 9\n",
      "693 10\n",
      "695 17\n",
      "697 3\n",
      "699 20\n",
      "701 9\n",
      "701 25\n",
      "703 6\n",
      "704 7\n",
      "705 32\n",
      "710 10\n",
      "711 17\n",
      "711 24\n",
      "714 21\n",
      "718 18\n",
      "723 30\n",
      "723 39\n",
      "734 2\n",
      "734 11\n",
      "734 12\n",
      "734 17\n",
      "736 0\n",
      "746 9\n",
      "766 2\n",
      "767 21\n",
      "768 10\n",
      "769 16\n",
      "770 9\n",
      "770 11\n",
      "771 15\n",
      "774 8\n",
      "774 18\n",
      "778 17\n",
      "779 6\n",
      "785 7\n",
      "785 9\n",
      "787 18\n",
      "791 9\n",
      "794 0\n",
      "801 0\n",
      "801 6\n",
      "801 14\n",
      "802 14\n",
      "802 16\n",
      "802 19\n",
      "803 19\n",
      "804 10\n",
      "805 13\n",
      "807 3\n",
      "809 3\n",
      "810 2\n",
      "810 23\n",
      "812 0\n",
      "812 5\n",
      "812 7\n",
      "814 4\n",
      "814 9\n",
      "814 14\n",
      "815 0\n",
      "819 10\n",
      "821 5\n",
      "824 1\n",
      "826 0\n",
      "827 8\n",
      "829 11\n",
      "830 13\n",
      "832 0\n",
      "832 9\n",
      "834 0\n",
      "836 7\n",
      "836 11\n",
      "836 12\n",
      "837 24\n",
      "839 13\n",
      "840 6\n",
      "840 9\n",
      "841 5\n",
      "841 6\n",
      "842 6\n",
      "845 1\n",
      "845 14\n",
      "846 0\n",
      "849 6\n",
      "850 9\n",
      "850 11\n",
      "853 0\n",
      "853 19\n",
      "856 4\n",
      "858 6\n",
      "861 9\n",
      "863 6\n",
      "865 9\n",
      "866 5\n",
      "867 7\n",
      "867 9\n",
      "867 14\n",
      "869 5\n",
      "870 5\n",
      "875 7\n",
      "876 12\n",
      "878 7\n",
      "880 10\n",
      "881 11\n",
      "882 7\n",
      "884 9\n",
      "885 0\n",
      "885 5\n",
      "886 3\n",
      "888 8\n",
      "890 15\n",
      "892 4\n",
      "892 11\n",
      "895 0\n",
      "896 0\n",
      "896 3\n",
      "899 11\n",
      "901 19\n",
      "902 1\n",
      "902 7\n",
      "904 4\n",
      "904 13\n",
      "905 4\n",
      "906 22\n",
      "912 12\n",
      "914 0\n",
      "914 10\n",
      "914 19\n",
      "915 0\n",
      "916 10\n",
      "919 0\n",
      "921 5\n",
      "922 10\n",
      "923 27\n",
      "925 9\n",
      "926 3\n",
      "929 7\n",
      "930 0\n",
      "930 9\n",
      "932 12\n",
      "935 2\n",
      "936 4\n",
      "939 6\n",
      "940 10\n",
      "940 15\n",
      "941 5\n",
      "943 7\n",
      "944 9\n",
      "945 6\n",
      "945 10\n",
      "946 3\n",
      "947 4\n",
      "947 15\n",
      "948 4\n",
      "948 7\n",
      "949 8\n",
      "950 5\n",
      "950 9\n",
      "950 17\n",
      "951 7\n",
      "953 1\n",
      "953 4\n",
      "954 14\n",
      "955 7\n",
      "961 24\n",
      "961 29\n",
      "963 31\n",
      "973 6\n",
      "973 9\n",
      "973 12\n",
      "973 15\n",
      "973 33\n",
      "975 9\n",
      "977 11\n",
      "978 8\n",
      "978 18\n",
      "980 15\n",
      "983 7\n",
      "985 8\n",
      "985 11\n",
      "986 11\n",
      "990 7\n",
      "990 19\n",
      "992 12\n",
      "995 2\n",
      "995 10\n",
      "995 13\n",
      "998 11\n",
      "998 16\n",
      "998 22\n",
      "999 7\n",
      "1000 11\n",
      "1001 0\n",
      "1001 9\n",
      "1002 1\n",
      "1003 20\n",
      "1005 3\n",
      "1005 11\n",
      "1007 22\n",
      "1009 1\n",
      "1009 7\n",
      "1013 10\n",
      "1013 18\n",
      "1014 7\n",
      "1015 12\n",
      "1017 18\n",
      "1019 18\n",
      "1020 3\n",
      "1022 8\n",
      "1023 14\n",
      "1023 19\n",
      "1024 6\n",
      "1024 9\n",
      "1024 23\n",
      "1026 17\n",
      "1028 2\n",
      "1028 11\n",
      "1028 18\n",
      "1029 15\n",
      "1029 18\n",
      "1029 20\n",
      "1029 24\n",
      "1030 19\n",
      "1030 39\n",
      "1031 2\n",
      "1031 11\n",
      "1031 36\n",
      "1032 4\n",
      "1032 12\n",
      "1032 16\n",
      "1033 3\n",
      "1033 7\n",
      "1034 13\n",
      "1035 1\n",
      "1036 2\n",
      "1036 19\n",
      "1037 8\n",
      "1037 12\n",
      "1037 21\n",
      "1037 38\n",
      "1038 3\n",
      "1039 42\n",
      "1044 5\n",
      "1050 25\n",
      "1051 0\n",
      "1053 6\n",
      "1054 23\n",
      "1056 0\n",
      "1058 36\n",
      "1059 7\n",
      "1061 5\n",
      "1061 17\n",
      "1062 22\n",
      "1064 0\n",
      "1065 14\n",
      "1066 2\n",
      "1067 2\n",
      "1068 23\n",
      "1068 27\n",
      "1070 12\n",
      "1071 8\n",
      "1073 11\n",
      "1074 0\n",
      "1075 4\n",
      "1076 13\n",
      "1077 16\n",
      "1077 26\n",
      "1079 4\n",
      "1083 6\n",
      "1085 16\n",
      "1086 20\n",
      "1089 17\n",
      "1094 14\n",
      "1095 0\n",
      "1097 8\n",
      "1099 13\n",
      "1101 4\n",
      "1103 2\n",
      "1106 17\n",
      "1106 25\n",
      "1109 12\n",
      "1109 18\n",
      "1110 0\n",
      "1110 13\n",
      "1110 15\n",
      "1110 27\n",
      "1110 34\n",
      "1111 4\n",
      "1112 11\n",
      "1113 15\n",
      "1117 11\n",
      "1118 11\n",
      "1119 16\n",
      "1120 15\n",
      "1120 22\n",
      "1121 11\n",
      "1122 6\n",
      "1123 23\n",
      "1124 16\n",
      "1124 20\n",
      "1125 0\n",
      "1125 27\n",
      "1126 15\n",
      "1127 4\n",
      "1130 11\n",
      "1131 6\n",
      "1132 0\n",
      "1132 14\n",
      "1135 4\n",
      "1137 5\n",
      "1138 14\n",
      "1138 23\n",
      "1138 36\n",
      "1140 9\n",
      "1141 4\n",
      "1143 34\n",
      "1145 13\n",
      "1145 31\n",
      "1146 5\n",
      "1147 15\n",
      "1148 17\n",
      "1149 0\n",
      "1151 0\n",
      "1151 14\n",
      "1153 13\n",
      "1154 0\n",
      "1154 4\n",
      "1154 6\n",
      "1160 32\n",
      "1163 19\n",
      "1164 3\n",
      "1165 6\n",
      "1166 3\n",
      "1166 9\n",
      "1168 4\n",
      "1169 20\n",
      "1170 5\n",
      "1171 4\n",
      "1173 6\n",
      "1173 9\n",
      "1174 9\n",
      "1175 0\n",
      "1176 2\n",
      "1176 8\n",
      "1177 9\n",
      "1177 15\n",
      "1177 17\n",
      "1178 1\n",
      "1179 21\n",
      "1180 9\n",
      "1180 20\n",
      "1183 27\n",
      "1185 2\n",
      "1186 8\n",
      "1188 6\n",
      "1190 11\n",
      "1191 10\n",
      "1191 16\n",
      "1191 25\n",
      "1193 8\n",
      "1194 10\n",
      "1195 1\n",
      "1195 8\n",
      "1197 19\n",
      "1197 24\n",
      "1199 0\n",
      "1202 11\n",
      "1202 31\n",
      "1203 16\n",
      "1204 7\n",
      "1204 8\n",
      "1206 5\n",
      "1207 3\n",
      "1207 7\n",
      "1208 3\n",
      "1208 10\n",
      "1211 13\n",
      "1211 21\n",
      "1213 0\n",
      "1213 8\n",
      "1215 13\n",
      "1215 26\n",
      "1215 28\n",
      "1218 1\n",
      "1221 26\n",
      "1222 9\n",
      "1226 18\n",
      "1227 13\n",
      "1231 17\n",
      "1233 6\n",
      "1233 10\n",
      "1234 13\n",
      "1235 5\n",
      "1235 14\n",
      "1238 2\n",
      "1238 10\n",
      "1240 2\n",
      "1240 7\n",
      "1241 9\n",
      "1242 7\n",
      "1243 0\n",
      "1243 4\n",
      "1245 15\n",
      "1245 25\n",
      "1247 6\n",
      "1247 19\n",
      "1250 5\n",
      "1251 8\n",
      "1253 8\n",
      "1254 3\n",
      "1254 8\n",
      "1255 9\n",
      "1256 0\n",
      "1257 3\n",
      "1258 5\n",
      "1258 8\n",
      "1258 11\n",
      "1258 13\n",
      "1259 0\n",
      "1259 2\n",
      "1263 19\n",
      "1264 7\n",
      "1266 13\n",
      "1268 14\n",
      "1271 7\n",
      "1281 5\n",
      "1282 32\n",
      "1289 0\n",
      "1291 2\n",
      "1292 0\n",
      "1293 0\n",
      "1293 13\n",
      "1296 0\n",
      "1297 12\n",
      "1306 7\n",
      "1312 22\n",
      "1313 12\n",
      "1319 15\n",
      "1320 14\n",
      "1321 9\n",
      "1322 12\n",
      "1322 15\n",
      "1324 9\n",
      "1324 17\n",
      "1326 5\n",
      "1326 12\n",
      "1328 6\n",
      "1329 36\n",
      "1332 8\n",
      "1332 15\n",
      "1332 19\n",
      "1333 0\n",
      "1334 7\n",
      "1334 11\n",
      "1334 12\n",
      "1334 27\n",
      "1335 0\n",
      "1335 12\n",
      "1335 16\n",
      "1336 0\n",
      "1337 0\n",
      "1338 15\n",
      "1340 13\n",
      "1341 1\n",
      "1341 21\n",
      "1341 24\n",
      "1342 19\n",
      "1343 3\n",
      "1343 6\n",
      "1343 8\n",
      "1345 15\n",
      "1348 12\n",
      "1348 34\n",
      "1349 11\n",
      "1350 0\n",
      "1351 9\n",
      "1351 18\n",
      "1354 0\n",
      "1355 3\n",
      "1355 22\n",
      "1355 24\n",
      "1356 12\n",
      "1358 28\n",
      "1359 16\n",
      "1360 3\n",
      "1362 5\n",
      "1362 9\n",
      "1364 15\n",
      "1365 5\n",
      "1367 8\n",
      "1368 7\n",
      "1371 9\n",
      "1374 6\n",
      "1374 10\n",
      "1376 12\n",
      "1377 1\n",
      "1377 4\n",
      "1378 1\n",
      "1378 3\n",
      "1380 9\n",
      "1382 19\n",
      "1383 18\n",
      "1384 11\n",
      "1385 13\n",
      "1386 12\n",
      "1388 1\n",
      "1391 6\n",
      "1392 18\n",
      "1393 5\n",
      "1393 24\n",
      "1395 2\n",
      "1395 28\n",
      "1398 12\n",
      "1399 3\n",
      "1400 0\n",
      "1406 3\n",
      "1407 1\n",
      "1411 2\n",
      "1419 8\n",
      "1419 16\n",
      "1419 20\n",
      "1420 1\n",
      "1423 13\n",
      "1423 17\n",
      "1430 0\n",
      "1431 1\n",
      "1433 11\n",
      "1434 12\n",
      "1437 6\n",
      "1439 18\n",
      "1439 25\n",
      "1440 10\n",
      "1444 1\n",
      "1449 12\n",
      "1450 32\n",
      "1452 26\n",
      "1452 27\n",
      "1453 1\n",
      "1453 6\n",
      "1457 0\n",
      "1457 14\n",
      "1458 1\n",
      "1459 8\n",
      "1459 23\n",
      "1461 18\n",
      "1466 2\n",
      "1468 20\n",
      "1469 9\n",
      "1469 14\n",
      "1471 23\n",
      "1471 24\n",
      "1474 5\n",
      "1475 1\n",
      "1477 4\n",
      "1482 0\n",
      "1484 10\n",
      "1484 22\n",
      "1485 3\n",
      "1490 0\n",
      "1491 15\n",
      "1494 2\n",
      "1495 14\n",
      "1496 14\n",
      "1497 17\n",
      "1498 0\n",
      "1502 0\n",
      "1502 7\n",
      "1502 16\n",
      "1502 25\n",
      "1503 2\n",
      "1504 8\n",
      "1505 5\n",
      "1506 0\n",
      "1506 13\n",
      "1506 22\n",
      "1507 18\n",
      "1508 3\n",
      "1508 8\n",
      "1508 24\n",
      "1508 26\n",
      "1509 6\n",
      "1510 18\n",
      "1512 3\n",
      "1513 13\n",
      "1515 0\n",
      "1516 4\n",
      "1516 5\n",
      "1516 8\n",
      "1519 0\n",
      "1519 6\n",
      "1519 9\n",
      "1519 12\n",
      "1519 15\n",
      "1520 0\n",
      "1520 2\n",
      "1522 0\n",
      "1522 12\n",
      "1524 0\n",
      "1528 9\n",
      "1528 11\n",
      "1529 0\n",
      "1530 22\n",
      "1532 21\n",
      "1534 9\n",
      "1538 4\n",
      "1538 5\n",
      "1540 7\n",
      "1540 15\n",
      "1541 2\n",
      "1544 25\n",
      "1544 28\n",
      "1545 0\n",
      "1546 1\n",
      "1549 0\n",
      "1550 23\n",
      "1555 11\n",
      "1562 31\n",
      "1564 0\n",
      "1564 4\n",
      "1565 3\n",
      "1567 0\n",
      "1569 16\n",
      "1569 18\n",
      "1569 26\n",
      "1570 5\n",
      "1572 8\n",
      "1572 25\n",
      "1576 5\n",
      "1577 16\n",
      "1578 11\n",
      "1580 4\n",
      "1582 6\n",
      "1584 6\n",
      "1585 6\n",
      "1585 10\n",
      "1587 0\n",
      "1588 0\n",
      "1589 29\n",
      "1592 0\n",
      "1592 4\n",
      "1592 12\n",
      "1592 25\n",
      "1593 0\n",
      "1593 5\n",
      "1594 0\n",
      "1594 8\n",
      "1594 20\n",
      "1595 3\n",
      "1595 16\n",
      "1596 5\n",
      "1597 5\n",
      "1597 10\n",
      "1598 0\n",
      "1598 13\n",
      "1598 24\n",
      "1600 6\n",
      "1600 9\n",
      "1600 12\n",
      "1600 20\n",
      "1600 22\n",
      "1601 9\n",
      "1602 0\n",
      "1602 13\n",
      "1602 16\n",
      "1602 18\n",
      "1603 5\n",
      "1605 4\n",
      "1605 6\n",
      "1605 13\n",
      "1607 3\n",
      "1607 12\n",
      "1608 0\n",
      "1608 12\n",
      "1611 13\n",
      "1613 0\n",
      "1614 10\n",
      "1615 25\n",
      "1615 26\n",
      "1618 8\n",
      "1619 0\n",
      "1621 6\n",
      "1621 15\n",
      "1621 23\n",
      "1626 11\n",
      "1627 1\n",
      "1629 28\n",
      "1629 36\n",
      "1630 0\n",
      "1630 5\n",
      "1630 11\n",
      "1631 4\n",
      "1631 5\n",
      "1631 16\n",
      "1631 24\n",
      "1632 9\n",
      "1633 5\n",
      "1634 6\n",
      "1634 7\n",
      "1635 8\n",
      "1636 2\n",
      "1637 4\n",
      "1639 4\n",
      "1639 22\n",
      "1640 24\n",
      "1642 31\n",
      "1646 14\n",
      "1650 12\n",
      "1655 5\n",
      "1656 7\n",
      "1660 9\n",
      "1661 10\n",
      "1661 12\n",
      "1663 0\n",
      "1664 7\n",
      "1665 12\n",
      "1667 2\n",
      "1670 7\n",
      "1670 24\n",
      "1671 11\n",
      "1675 9\n",
      "1675 22\n",
      "1675 24\n",
      "1676 20\n",
      "1677 20\n",
      "1677 22\n",
      "1679 20\n",
      "1679 23\n",
      "1679 30\n",
      "1679 36\n",
      "1680 0\n",
      "1680 24\n",
      "1681 33\n",
      "1682 17\n",
      "1683 0\n",
      "1684 20\n",
      "1685 24\n",
      "1687 0\n",
      "1688 17\n",
      "1691 0\n",
      "1692 8\n",
      "1693 32\n",
      "1697 8\n",
      "1701 12\n",
      "1701 19\n",
      "1703 0\n",
      "1704 14\n",
      "1705 16\n",
      "1707 0\n",
      "1711 5\n",
      "1712 10\n",
      "1712 17\n",
      "1712 22\n",
      "1714 5\n",
      "1714 19\n",
      "1716 11\n",
      "1717 4\n",
      "1721 7\n",
      "1721 18\n",
      "1723 16\n",
      "1724 9\n",
      "1727 2\n",
      "1727 7\n",
      "1729 8\n",
      "1731 20\n",
      "1738 11\n",
      "1739 0\n",
      "1744 0\n",
      "1748 0\n",
      "1749 5\n",
      "1757 1\n",
      "1762 15\n",
      "1771 9\n",
      "1772 0\n",
      "1772 10\n",
      "1773 1\n",
      "1780 18\n",
      "1781 0\n",
      "1782 38\n",
      "1790 0\n",
      "1792 5\n",
      "1794 9\n",
      "1797 5\n",
      "1797 9\n",
      "1798 8\n",
      "1799 18\n",
      "1800 8\n",
      "1804 22\n",
      "1809 23\n",
      "1809 26\n",
      "1810 2\n",
      "1810 13\n",
      "1811 18\n",
      "1812 15\n",
      "1812 17\n",
      "1813 3\n",
      "1815 27\n",
      "1817 0\n",
      "1819 20\n",
      "1819 22\n",
      "1822 0\n",
      "1822 2\n",
      "1822 5\n",
      "1822 14\n",
      "1825 23\n",
      "1827 12\n",
      "1832 5\n",
      "1835 8\n",
      "1835 9\n",
      "1836 7\n",
      "1837 7\n",
      "1837 14\n",
      "1837 17\n",
      "1837 19\n",
      "1837 24\n",
      "1838 3\n",
      "1840 5\n",
      "1840 12\n",
      "1840 18\n",
      "1846 13\n",
      "1847 11\n",
      "1848 4\n",
      "1848 13\n",
      "1851 0\n",
      "1857 5\n",
      "1857 9\n",
      "1857 10\n",
      "1858 12\n",
      "1860 0\n",
      "1862 10\n",
      "1866 0\n",
      "1870 5\n",
      "1870 13\n",
      "1870 17\n",
      "1870 18\n",
      "1871 25\n",
      "1876 8\n",
      "1880 27\n",
      "1889 2\n",
      "1890 6\n",
      "1898 12\n",
      "1901 31\n",
      "1909 11\n",
      "1912 0\n",
      "1912 6\n",
      "1914 2\n",
      "1914 21\n",
      "1915 7\n",
      "1915 9\n",
      "1917 4\n",
      "1917 12\n",
      "1917 14\n",
      "1918 5\n",
      "1920 2\n",
      "1920 15\n",
      "1921 20\n",
      "1921 26\n",
      "1923 6\n",
      "1928 3\n",
      "1928 4\n",
      "1928 12\n",
      "1928 17\n",
      "1928 25\n",
      "1931 5\n",
      "1933 2\n",
      "1938 1\n",
      "1938 20\n",
      "1942 11\n",
      "1942 20\n",
      "1943 10\n",
      "1947 6\n",
      "1949 0\n",
      "1949 11\n",
      "1949 12\n",
      "1949 28\n",
      "1951 2\n",
      "1951 15\n",
      "1952 2\n",
      "1952 6\n",
      "1952 17\n",
      "1953 21\n",
      "1956 20\n",
      "1956 22\n",
      "1957 0\n",
      "1958 3\n",
      "1960 2\n",
      "1964 2\n",
      "1969 10\n",
      "1969 13\n",
      "1971 12\n",
      "1974 0\n",
      "1974 11\n",
      "1974 12\n",
      "1975 19\n",
      "1978 9\n",
      "1980 21\n",
      "1980 23\n",
      "1984 25\n",
      "1984 26\n",
      "1989 0\n",
      "1993 3\n",
      "1996 0\n",
      "1997 3\n",
      "1998 10\n",
      "1998 23\n",
      "1999 2\n",
      "2003 8\n",
      "2003 9\n",
      "2008 2\n",
      "2010 10\n",
      "2010 14\n",
      "2012 0\n",
      "2012 12\n",
      "2012 25\n",
      "2013 19\n",
      "2015 15\n",
      "2017 6\n",
      "2019 20\n",
      "2019 22\n",
      "2022 3\n",
      "2024 10\n",
      "2025 9\n",
      "2035 9\n",
      "2046 18\n",
      "2048 8\n",
      "2050 1\n",
      "2052 11\n",
      "2055 21\n",
      "2057 0\n",
      "2061 0\n",
      "2062 33\n",
      "2064 0\n",
      "2068 15\n",
      "2070 3\n",
      "2071 17\n",
      "2071 19\n",
      "2074 1\n",
      "2075 6\n",
      "2078 0\n",
      "2083 0\n",
      "2090 22\n",
      "2090 34\n",
      "2091 2\n",
      "2091 15\n",
      "2092 5\n",
      "2092 27\n",
      "2100 2\n",
      "2103 4\n",
      "2104 0\n",
      "2106 7\n",
      "2109 12\n",
      "2109 21\n",
      "2114 2\n",
      "2114 14\n",
      "2115 3\n",
      "2119 23\n",
      "2120 4\n",
      "2120 15\n",
      "2121 21\n",
      "2122 1\n",
      "2122 22\n",
      "2123 8\n",
      "2123 21\n",
      "2123 24\n",
      "2123 27\n",
      "2125 6\n",
      "2125 23\n",
      "2134 13\n",
      "2134 33\n",
      "2136 32\n",
      "2136 33\n",
      "2136 35\n",
      "2136 37\n",
      "2139 16\n",
      "2141 8\n",
      "2141 19\n",
      "2142 0\n",
      "2142 17\n",
      "2143 4\n",
      "2143 16\n",
      "2144 2\n",
      "2144 19\n",
      "2144 32\n",
      "2145 23\n",
      "2147 0\n",
      "2149 0\n",
      "2151 0\n",
      "2152 6\n",
      "2153 0\n",
      "2155 6\n",
      "2156 6\n",
      "2156 10\n",
      "2157 0\n",
      "2157 9\n",
      "2157 17\n",
      "2158 0\n",
      "2158 8\n",
      "2159 19\n",
      "2161 6\n",
      "2162 1\n",
      "2163 9\n",
      "2164 16\n",
      "2167 7\n",
      "2168 7\n",
      "2168 10\n",
      "2169 7\n",
      "2169 10\n",
      "2170 10\n",
      "2174 11\n",
      "2177 24\n",
      "2178 6\n",
      "2179 18\n",
      "2181 0\n",
      "2185 1\n",
      "2188 3\n",
      "2188 9\n",
      "2188 14\n",
      "2189 10\n",
      "2189 21\n",
      "2191 0\n",
      "2191 17\n",
      "2192 18\n",
      "2193 14\n",
      "2200 6\n",
      "2204 0\n",
      "2206 12\n",
      "2209 24\n",
      "2211 0\n",
      "2217 8\n",
      "2221 0\n",
      "2221 2\n",
      "2221 12\n",
      "2223 0\n",
      "2224 5\n",
      "2226 17\n",
      "2227 4\n",
      "2228 3\n",
      "2228 9\n",
      "2230 8\n",
      "2232 7\n",
      "2234 16\n",
      "2237 18\n",
      "2238 1\n",
      "2239 20\n",
      "2241 4\n",
      "2248 7\n",
      "2248 15\n",
      "2249 18\n",
      "2249 21\n",
      "2250 15\n",
      "2251 0\n",
      "2252 0\n",
      "2253 1\n",
      "2254 14\n",
      "2255 11\n",
      "2258 0\n",
      "2262 2\n",
      "2262 6\n",
      "2262 8\n",
      "2267 8\n",
      "2269 6\n",
      "2270 11\n",
      "2271 8\n",
      "2271 12\n",
      "2271 13\n",
      "2274 0\n",
      "2275 2\n",
      "2278 0\n",
      "2278 13\n",
      "2279 12\n",
      "2280 4\n",
      "2281 0\n",
      "2284 19\n",
      "2285 0\n",
      "2289 4\n",
      "2291 0\n",
      "2291 8\n",
      "2291 10\n",
      "2295 0\n",
      "2301 0\n",
      "2304 18\n",
      "2308 2\n",
      "2314 10\n",
      "2315 15\n",
      "2316 5\n",
      "2317 0\n",
      "2317 7\n",
      "2321 4\n",
      "2324 1\n",
      "2328 0\n",
      "2329 15\n",
      "2330 15\n",
      "2331 10\n",
      "2334 4\n",
      "2334 6\n",
      "2335 4\n",
      "2335 6\n",
      "2335 16\n",
      "2337 4\n",
      "2340 4\n",
      "2340 6\n",
      "2341 4\n",
      "2341 23\n",
      "2343 18\n",
      "2344 0\n",
      "2345 19\n",
      "2347 10\n",
      "2348 0\n",
      "2352 6\n",
      "2353 0\n",
      "2353 2\n",
      "2355 4\n",
      "2359 0\n",
      "2360 0\n",
      "2361 7\n",
      "2362 0\n",
      "2363 4\n",
      "2364 0\n",
      "2365 0\n",
      "2366 30\n",
      "2367 9\n",
      "2372 13\n",
      "2380 2\n",
      "2381 16\n",
      "2381 23\n",
      "2382 6\n",
      "2384 16\n",
      "2384 21\n",
      "2385 6\n",
      "2386 14\n",
      "2387 4\n",
      "2387 28\n",
      "2390 0\n",
      "2393 0\n",
      "2394 6\n",
      "2395 5\n",
      "2395 9\n",
      "2401 22\n",
      "2404 17\n",
      "2407 11\n",
      "2412 7\n",
      "2413 12\n",
      "2414 20\n",
      "2415 0\n",
      "2418 0\n",
      "2418 5\n",
      "2419 8\n",
      "2420 12\n",
      "2421 0\n",
      "2421 13\n",
      "2421 15\n",
      "2424 0\n",
      "2425 5\n",
      "2434 0\n",
      "2434 13\n",
      "2434 20\n",
      "2434 25\n",
      "2435 6\n",
      "2435 8\n",
      "2435 17\n",
      "2440 12\n",
      "2442 12\n",
      "2443 2\n",
      "2445 9\n",
      "2449 7\n",
      "2452 8\n",
      "2452 11\n",
      "2454 10\n",
      "2457 4\n",
      "2457 5\n",
      "2457 17\n",
      "2457 20\n",
      "2461 18\n",
      "2463 6\n",
      "2465 2\n",
      "2467 0\n",
      "2471 5\n",
      "2472 9\n",
      "2473 4\n",
      "2475 6\n",
      "2477 8\n",
      "2480 10\n",
      "2481 15\n",
      "2481 17\n",
      "2482 12\n",
      "2483 0\n",
      "2483 5\n",
      "2484 11\n",
      "2489 25\n",
      "2490 12\n",
      "2491 14\n",
      "2491 16\n",
      "2494 8\n",
      "2496 3\n",
      "2496 10\n",
      "2497 0\n",
      "2500 13\n",
      "2503 9\n",
      "2505 0\n",
      "2505 4\n",
      "2506 0\n",
      "2506 5\n",
      "2507 18\n",
      "2508 7\n",
      "2509 2\n",
      "2509 14\n",
      "2509 45\n",
      "2510 9\n",
      "2510 13\n",
      "2513 11\n",
      "2513 13\n",
      "2515 10\n",
      "2515 12\n",
      "2516 0\n",
      "2518 4\n",
      "2520 0\n",
      "2522 7\n",
      "2524 8\n",
      "2526 14\n",
      "2527 0\n",
      "2534 3\n",
      "2535 2\n",
      "2536 1\n",
      "2538 4\n",
      "2540 7\n",
      "2541 5\n",
      "2548 0\n",
      "2549 0\n",
      "2554 11\n",
      "2554 16\n",
      "2562 10\n",
      "2563 17\n",
      "2565 22\n",
      "2565 24\n",
      "2565 25\n",
      "2567 18\n",
      "2568 10\n",
      "2574 2\n",
      "2577 13\n",
      "2578 3\n",
      "2579 0\n",
      "2580 19\n",
      "2581 0\n",
      "2582 0\n",
      "2585 19\n",
      "2586 10\n",
      "2587 0\n",
      "2588 7\n",
      "2589 9\n",
      "2590 10\n",
      "2592 0\n",
      "2592 1\n",
      "2592 7\n",
      "2592 13\n",
      "2592 15\n",
      "2593 7\n",
      "2597 0\n",
      "2605 6\n",
      "2614 5\n",
      "2618 0\n",
      "2619 7\n",
      "2620 8\n",
      "2621 8\n",
      "2622 16\n",
      "2622 21\n",
      "2623 8\n",
      "2625 7\n",
      "2626 16\n",
      "2628 2\n",
      "2628 17\n",
      "2630 5\n",
      "2631 2\n",
      "2636 1\n",
      "2637 10\n",
      "2641 8\n",
      "2642 1\n",
      "2642 2\n",
      "2644 5\n",
      "2649 7\n",
      "2654 7\n",
      "2655 1\n",
      "2656 17\n",
      "2657 0\n",
      "2658 13\n",
      "2659 10\n",
      "2660 4\n",
      "2661 12\n",
      "2661 17\n",
      "2662 4\n",
      "2663 7\n",
      "2663 12\n",
      "2664 3\n",
      "2665 14\n",
      "2666 12\n",
      "2666 17\n",
      "2667 4\n",
      "2668 2\n",
      "2670 4\n",
      "2670 34\n",
      "2671 4\n",
      "2672 0\n",
      "2679 0\n",
      "2681 6\n",
      "2682 11\n",
      "2682 13\n",
      "2684 14\n",
      "2690 7\n",
      "2691 4\n",
      "2694 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2694 8\n",
      "2695 0\n",
      "2697 2\n",
      "2698 18\n",
      "2699 8\n",
      "2702 7\n",
      "2702 13\n",
      "2702 17\n",
      "2703 15\n",
      "2704 10\n",
      "2705 6\n",
      "2705 8\n",
      "2706 3\n",
      "2707 4\n",
      "2708 1\n",
      "2709 33\n",
      "2715 0\n",
      "2719 25\n",
      "2727 5\n",
      "2736 0\n",
      "2739 17\n",
      "2741 9\n",
      "2748 0\n",
      "2752 2\n",
      "2752 6\n",
      "2752 8\n",
      "2757 8\n",
      "2760 11\n",
      "2761 8\n",
      "2761 12\n",
      "2761 13\n",
      "2764 0\n",
      "2771 7\n",
      "2773 0\n",
      "2774 26\n",
      "2774 37\n",
      "2779 8\n",
      "2779 28\n",
      "2780 9\n",
      "2780 10\n",
      "2781 20\n",
      "2781 23\n",
      "2781 26\n",
      "2782 2\n",
      "2782 4\n",
      "2783 18\n",
      "2784 1\n",
      "2785 7\n",
      "2785 13\n",
      "2786 7\n",
      "2788 10\n",
      "2788 19\n",
      "2790 4\n",
      "2792 16\n",
      "2794 11\n",
      "2795 22\n",
      "2795 27\n",
      "2795 31\n",
      "2796 0\n",
      "2798 3\n",
      "2798 9\n",
      "2798 34\n",
      "2799 1\n",
      "2799 21\n",
      "2800 3\n",
      "2800 9\n",
      "2801 15\n",
      "2803 15\n",
      "2804 8\n",
      "2804 10\n",
      "2804 22\n",
      "2806 19\n",
      "2807 0\n",
      "2807 12\n",
      "2807 18\n",
      "2811 15\n",
      "2812 11\n",
      "2814 3\n",
      "2815 3\n",
      "2816 3\n",
      "2818 6\n",
      "2819 0\n",
      "2819 19\n",
      "2822 9\n",
      "2825 16\n",
      "2826 0\n",
      "2827 6\n",
      "2829 6\n",
      "2829 12\n",
      "2829 16\n",
      "2833 11\n",
      "2835 9\n",
      "2838 9\n",
      "2839 15\n",
      "2840 0\n",
      "2841 0\n",
      "2841 7\n",
      "2844 0\n",
      "2845 8\n",
      "2847 14\n",
      "2848 10\n",
      "2850 8\n",
      "2850 21\n",
      "2853 9\n",
      "2854 3\n",
      "2854 11\n",
      "2855 0\n",
      "2857 24\n",
      "2861 2\n",
      "2865 0\n",
      "2868 19\n",
      "2869 12\n",
      "2870 14\n",
      "2871 0\n",
      "2876 23\n",
      "2879 0\n",
      "2879 7\n",
      "2883 5\n",
      "2885 7\n",
      "2885 15\n",
      "2885 21\n",
      "2886 13\n",
      "2889 22\n",
      "2892 2\n",
      "2894 12\n",
      "2899 5\n",
      "2901 8\n",
      "2901 20\n",
      "2901 33\n",
      "2908 0\n",
      "2909 1\n",
      "2910 14\n",
      "2910 23\n",
      "2913 8\n",
      "2914 4\n",
      "2916 14\n",
      "2917 25\n",
      "2918 10\n",
      "2919 3\n",
      "2919 7\n",
      "2919 9\n",
      "2920 7\n",
      "2920 9\n",
      "2922 1\n",
      "2922 13\n",
      "2924 2\n",
      "2925 16\n",
      "2925 23\n",
      "2926 6\n",
      "2928 16\n",
      "2928 21\n",
      "2929 6\n",
      "2930 14\n",
      "2931 4\n",
      "2931 28\n",
      "2936 16\n",
      "2938 1\n",
      "2939 1\n",
      "2939 33\n",
      "2941 15\n",
      "2941 18\n",
      "2949 3\n",
      "2950 0\n",
      "2950 4\n",
      "2950 11\n",
      "2951 15\n",
      "2952 39\n",
      "2952 44\n",
      "2954 16\n",
      "2954 17\n",
      "2954 28\n",
      "2954 32\n",
      "2955 18\n",
      "2956 11\n",
      "2956 14\n",
      "2956 21\n",
      "2957 15\n",
      "2957 21\n",
      "2958 17\n",
      "2958 36\n",
      "2959 5\n",
      "2961 0\n",
      "2961 8\n",
      "2962 4\n",
      "2963 6\n",
      "2963 14\n",
      "2963 26\n",
      "2964 12\n",
      "2964 15\n",
      "2965 11\n",
      "2966 1\n",
      "2966 3\n",
      "2966 4\n",
      "2966 10\n",
      "2967 4\n",
      "2967 23\n",
      "2968 3\n",
      "2969 6\n",
      "2971 13\n",
      "2972 2\n",
      "2972 4\n",
      "2973 3\n",
      "2974 11\n",
      "2974 18\n",
      "2978 3\n",
      "2980 13\n",
      "2980 18\n",
      "2982 7\n",
      "2983 3\n",
      "2983 9\n",
      "2984 25\n",
      "2986 17\n",
      "2988 13\n",
      "2988 26\n",
      "2989 11\n",
      "2992 9\n",
      "2994 8\n",
      "2994 13\n",
      "2995 7\n",
      "2995 9\n",
      "2996 4\n",
      "2996 9\n",
      "2998 14\n",
      "3000 0\n",
      "3000 8\n",
      "3003 3\n",
      "3004 21\n",
      "3005 7\n",
      "3006 14\n",
      "3008 3\n",
      "3009 1\n",
      "3010 2\n",
      "3010 7\n",
      "3010 18\n",
      "3014 10\n",
      "3014 14\n",
      "3022 8\n",
      "3022 17\n",
      "3023 10\n",
      "3026 7\n",
      "3029 11\n",
      "3031 15\n",
      "3035 10\n",
      "3039 9\n",
      "3039 11\n",
      "3040 28\n",
      "3050 19\n",
      "3053 7\n",
      "3054 15\n",
      "3059 16\n",
      "3065 22\n",
      "3066 0\n",
      "3066 17\n",
      "3072 6\n",
      "3073 7\n",
      "3073 10\n",
      "3075 5\n",
      "3077 10\n",
      "3078 3\n",
      "3079 3\n",
      "3081 8\n",
      "3086 19\n",
      "3086 21\n",
      "3089 0\n",
      "3089 15\n",
      "3091 2\n",
      "3092 12\n",
      "3093 1\n",
      "3093 12\n",
      "3094 1\n",
      "3095 3\n",
      "3096 5\n",
      "3096 7\n",
      "3097 9\n",
      "3098 0\n",
      "3099 7\n",
      "3100 20\n",
      "3101 12\n",
      "3105 3\n",
      "3106 19\n",
      "3107 2\n",
      "3109 0\n",
      "3109 3\n",
      "3109 8\n",
      "3110 9\n",
      "3110 13\n",
      "3111 1\n",
      "3111 15\n",
      "3115 6\n",
      "3116 12\n",
      "3124 0\n",
      "3124 8\n",
      "3125 1\n",
      "3131 2\n",
      "3131 21\n",
      "3134 0\n",
      "3134 3\n",
      "3135 18\n",
      "3137 4\n",
      "3137 7\n",
      "3137 15\n",
      "3138 16\n",
      "3140 6\n",
      "3141 3\n",
      "3141 8\n",
      "3141 17\n",
      "3144 6\n",
      "3144 18\n",
      "3147 6\n",
      "3147 15\n",
      "3151 3\n",
      "3157 18\n",
      "3157 20\n",
      "3157 22\n",
      "3158 2\n",
      "3160 4\n",
      "3163 6\n",
      "3163 15\n",
      "3163 25\n",
      "3164 20\n",
      "3167 5\n",
      "3172 0\n",
      "3179 1\n",
      "3184 10\n",
      "3188 3\n",
      "3190 13\n",
      "3190 14\n",
      "3190 23\n",
      "3191 7\n",
      "3193 20\n",
      "3194 0\n",
      "3196 15\n",
      "3197 0\n",
      "3199 0\n",
      "3200 1\n",
      "3200 11\n",
      "3206 5\n",
      "3208 0\n",
      "3209 6\n",
      "3210 6\n",
      "3212 0\n",
      "3212 44\n",
      "3215 12\n",
      "3219 2\n",
      "3221 34\n",
      "3223 14\n",
      "3224 2\n",
      "3224 12\n",
      "3227 0\n",
      "3227 2\n",
      "3228 7\n",
      "3229 28\n",
      "3230 4\n",
      "3230 13\n",
      "3231 6\n",
      "3233 14\n",
      "3237 13\n",
      "3240 15\n",
      "3242 4\n",
      "3244 13\n",
      "3249 8\n",
      "3252 2\n",
      "3254 10\n",
      "3256 6\n",
      "3257 9\n",
      "3258 12\n",
      "3259 15\n",
      "3261 7\n",
      "3269 8\n",
      "3269 21\n",
      "3269 31\n",
      "3271 0\n",
      "3273 0\n",
      "3274 16\n",
      "3275 1\n",
      "3275 8\n",
      "3275 15\n",
      "3278 0\n",
      "3280 10\n",
      "3281 3\n",
      "3281 20\n",
      "3283 1\n",
      "3284 3\n",
      "3285 2\n",
      "3286 7\n",
      "3287 19\n",
      "3296 0\n",
      "3296 7\n",
      "3297 0\n",
      "3299 10\n",
      "3300 6\n",
      "3301 10\n",
      "3302 12\n",
      "3302 20\n",
      "3303 0\n",
      "3308 0\n",
      "3315 6\n",
      "3315 15\n",
      "3320 0\n",
      "3320 6\n",
      "3322 24\n",
      "3324 26\n",
      "3327 3\n",
      "3330 8\n",
      "3332 25\n",
      "3332 26\n",
      "3334 16\n",
      "3337 19\n",
      "3338 13\n",
      "3338 14\n",
      "3339 12\n",
      "3340 9\n",
      "3342 0\n",
      "3344 26\n",
      "3344 36\n",
      "3346 32\n",
      "3348 16\n",
      "3349 4\n",
      "3350 5\n",
      "3353 1\n",
      "3358 0\n",
      "3369 8\n",
      "3372 11\n",
      "3375 8\n",
      "3376 0\n",
      "3377 0\n",
      "3377 14\n",
      "3380 23\n",
      "3391 2\n",
      "3392 24\n",
      "3394 8\n",
      "3396 6\n",
      "3400 15\n",
      "3400 16\n",
      "3402 4\n",
      "3403 20\n",
      "3405 13\n",
      "3409 2\n",
      "3409 15\n",
      "3412 21\n",
      "3413 9\n",
      "3414 1\n",
      "3417 0\n",
      "3419 4\n",
      "3420 13\n",
      "3422 6\n",
      "3423 3\n",
      "3425 19\n",
      "3427 6\n",
      "3431 1\n",
      "3432 1\n",
      "3433 12\n",
      "3434 18\n",
      "3435 4\n",
      "3436 2\n",
      "3440 0\n",
      "3440 18\n",
      "3443 3\n",
      "3443 9\n",
      "3445 6\n",
      "3446 10\n",
      "3446 16\n",
      "3447 0\n",
      "3449 1\n",
      "3449 6\n",
      "3450 12\n",
      "3452 2\n",
      "3452 16\n",
      "3452 20\n",
      "3453 1\n",
      "3453 4\n",
      "3453 9\n",
      "3454 11\n",
      "3456 0\n",
      "3456 8\n",
      "3457 8\n",
      "3458 3\n",
      "3459 7\n",
      "3459 18\n",
      "3460 3\n",
      "3461 0\n",
      "3464 1\n",
      "3465 25\n",
      "3466 3\n",
      "3468 5\n",
      "3469 2\n",
      "3471 1\n",
      "3471 5\n",
      "3477 6\n",
      "3477 15\n",
      "3477 42\n",
      "3478 16\n",
      "3478 17\n",
      "3478 35\n",
      "3480 20\n",
      "3481 3\n",
      "3482 8\n",
      "3485 35\n",
      "3487 10\n",
      "3488 7\n",
      "3489 7\n",
      "3493 19\n",
      "3493 22\n",
      "3495 8\n",
      "3498 6\n",
      "3498 25\n",
      "3498 35\n",
      "3499 13\n",
      "3502 7\n",
      "3502 9\n",
      "3502 18\n",
      "3503 3\n",
      "3505 16\n",
      "3506 8\n",
      "3506 16\n",
      "3509 17\n",
      "3513 0\n",
      "3513 3\n",
      "3514 0\n",
      "3514 9\n",
      "3515 3\n",
      "3516 0\n",
      "3516 5\n",
      "3517 7\n",
      "3518 5\n",
      "3519 13\n",
      "3522 1\n",
      "3523 10\n",
      "3525 12\n",
      "3527 1\n",
      "3528 0\n",
      "3530 1\n",
      "3534 3\n",
      "3535 9\n",
      "3537 0\n",
      "3538 16\n",
      "3540 8\n",
      "3544 0\n",
      "3545 3\n",
      "3546 5\n",
      "3547 0\n",
      "3548 20\n",
      "3550 2\n",
      "3550 5\n",
      "3551 7\n",
      "3552 10\n",
      "3554 0\n",
      "3558 0\n",
      "3559 29\n",
      "3559 34\n",
      "3567 5\n",
      "3568 24\n",
      "3568 25\n",
      "3570 27\n",
      "3571 1\n",
      "3571 5\n",
      "3573 27\n",
      "3574 15\n",
      "3574 16\n",
      "3575 2\n",
      "3576 5\n",
      "3579 16\n",
      "3581 0\n",
      "3581 4\n",
      "3585 12\n",
      "3587 4\n",
      "3588 3\n",
      "3589 38\n",
      "3591 23\n",
      "3592 7\n",
      "3593 0\n",
      "3594 12\n",
      "3595 8\n",
      "3596 3\n",
      "3599 8\n",
      "3599 24\n",
      "3601 19\n",
      "3603 8\n",
      "3603 10\n",
      "3605 2\n",
      "3606 13\n",
      "3606 21\n",
      "3606 24\n",
      "3608 39\n",
      "3609 14\n",
      "3609 19\n",
      "3610 31\n",
      "3611 15\n",
      "3613 0\n",
      "3613 15\n",
      "3615 19\n",
      "3615 21\n",
      "3616 2\n",
      "3616 13\n",
      "3616 25\n",
      "3617 0\n",
      "3620 11\n",
      "3621 3\n",
      "3624 8\n",
      "3624 14\n",
      "3625 20\n",
      "3626 7\n",
      "3626 14\n",
      "3626 20\n",
      "3627 5\n",
      "3634 7\n",
      "3634 33\n",
      "3635 10\n",
      "3636 30\n",
      "3640 9\n",
      "3644 9\n",
      "3648 1\n",
      "3649 5\n",
      "3650 3\n",
      "3654 11\n",
      "3654 14\n",
      "3657 5\n",
      "3657 6\n",
      "3658 13\n",
      "3660 0\n",
      "3662 3\n",
      "3666 23\n",
      "3668 12\n",
      "3671 21\n",
      "3671 28\n",
      "3673 3\n",
      "3674 1\n",
      "3676 8\n",
      "3691 14\n",
      "3695 0\n",
      "3697 4\n",
      "3699 3\n",
      "3700 10\n",
      "3700 12\n",
      "3708 18\n",
      "3708 19\n",
      "3713 0\n",
      "3713 2\n",
      "3714 0\n",
      "3714 1\n",
      "3715 33\n",
      "3715 40\n",
      "3715 42\n",
      "3716 4\n",
      "3717 13\n",
      "3718 0\n",
      "3719 61\n",
      "3719 65\n",
      "3720 0\n",
      "3720 32\n",
      "3721 18\n",
      "3721 21\n",
      "3721 45\n",
      "3723 18\n",
      "3723 40\n",
      "3725 0\n",
      "3731 3\n",
      "3733 21\n",
      "3734 41\n",
      "3736 0\n",
      "3736 25\n",
      "3737 21\n",
      "3738 16\n",
      "3740 18\n",
      "3741 30\n",
      "3746 21\n",
      "3753 13\n",
      "3753 41\n",
      "3754 14\n",
      "3758 42\n",
      "3759 7\n",
      "3759 12\n",
      "3759 22\n",
      "3760 10\n",
      "3760 17\n",
      "3760 25\n",
      "3762 16\n",
      "3764 20\n",
      "3764 22\n",
      "3765 8\n",
      "3766 0\n",
      "3766 17\n",
      "3767 5\n",
      "3768 12\n",
      "3770 4\n",
      "3772 3\n",
      "3773 10\n",
      "3776 0\n",
      "3777 3\n",
      "3781 0\n",
      "3782 9\n",
      "3783 7\n",
      "3789 43\n",
      "3791 1\n",
      "3791 2\n",
      "3796 4\n",
      "3797 8\n",
      "3799 5\n",
      "3800 12\n",
      "3802 14\n",
      "3804 6\n",
      "3807 0\n",
      "3811 29\n",
      "3814 2\n",
      "3815 4\n",
      "3817 12\n",
      "3820 15\n",
      "3825 11\n",
      "3827 1\n",
      "3835 22\n",
      "3839 8\n",
      "3839 12\n",
      "3843 11\n",
      "3852 0\n",
      "3856 0\n",
      "3859 8\n",
      "3859 11\n",
      "3859 29\n",
      "3859 33\n",
      "3860 10\n",
      "3880 7\n",
      "3883 8\n",
      "3899 2\n",
      "3900 11\n",
      "3901 0\n",
      "3904 7\n",
      "3907 10\n",
      "3915 0\n",
      "3915 7\n",
      "3916 0\n",
      "3921 0\n",
      "3941 8\n",
      "3945 4\n",
      "3947 11\n",
      "3949 0\n",
      "3952 0\n",
      "3956 10\n",
      "3962 4\n",
      "3977 0\n",
      "3989 0\n",
      "3990 14\n",
      "3991 2\n",
      "3998 2\n",
      "3999 3\n",
      "4007 12\n",
      "4010 9\n",
      "4010 10\n",
      "4023 0\n",
      "4024 11\n",
      "4025 0\n",
      "4029 0\n",
      "4029 9\n",
      "4030 0\n",
      "4032 4\n",
      "4038 0\n",
      "4043 12\n",
      "4050 0\n",
      "4056 0\n",
      "4067 12\n",
      "4069 2\n",
      "4079 0\n",
      "4084 0\n",
      "4084 9\n",
      "4088 15\n",
      "4099 14\n",
      "4101 15\n",
      "4101 16\n",
      "4115 7\n",
      "4116 2\n",
      "4122 2\n",
      "4125 0\n",
      "4126 0\n",
      "4126 4\n",
      "4127 3\n",
      "4131 8\n",
      "4131 14\n",
      "4135 0\n",
      "4137 31\n",
      "4138 6\n",
      "4138 9\n",
      "4138 37\n",
      "4140 5\n",
      "4142 26\n",
      "4143 0\n",
      "4149 0\n",
      "4151 11\n",
      "4151 27\n",
      "4152 3\n",
      "4153 0\n",
      "4158 0\n",
      "4163 3\n",
      "4170 0\n",
      "4173 8\n",
      "4174 17\n",
      "4179 14\n",
      "4183 13\n",
      "4185 13\n",
      "4187 17\n",
      "4188 12\n",
      "4189 0\n",
      "4190 26\n",
      "4191 15\n",
      "4192 13\n",
      "4194 0\n",
      "4195 18\n",
      "4199 10\n",
      "4200 4\n",
      "4200 19\n",
      "4200 25\n",
      "4201 28\n",
      "4203 5\n",
      "4205 10\n",
      "4205 15\n",
      "4206 9\n",
      "4207 6\n",
      "4212 6\n",
      "4213 22\n",
      "4216 6\n",
      "4217 17\n",
      "4218 5\n",
      "4218 7\n",
      "4218 10\n",
      "4219 19\n",
      "4220 1\n",
      "4223 0\n",
      "4223 1\n",
      "4229 11\n",
      "4239 1\n",
      "4239 2\n",
      "4239 3\n",
      "4240 8\n",
      "4240 9\n",
      "4241 1\n",
      "4241 2\n",
      "4241 15\n",
      "4262 1\n",
      "4266 6\n",
      "4270 2\n",
      "4273 17\n",
      "4273 28\n",
      "4275 11\n",
      "4276 29\n",
      "4277 17\n",
      "4278 5\n",
      "4279 23\n",
      "4279 25\n",
      "4284 17\n",
      "4290 24\n",
      "4291 17\n",
      "4293 3\n",
      "4294 0\n",
      "4294 3\n",
      "4295 6\n",
      "4295 13\n",
      "4296 9\n",
      "4296 11\n",
      "4297 6\n",
      "4298 9\n",
      "4299 0\n",
      "4300 9\n",
      "4301 13\n",
      "4302 2\n",
      "4304 3\n",
      "4305 0\n",
      "4305 12\n",
      "4306 24\n",
      "4306 30\n",
      "4307 7\n",
      "4308 0\n",
      "4308 2\n",
      "4309 16\n",
      "4310 2\n",
      "4311 34\n",
      "4312 5\n",
      "4318 10\n",
      "4328 2\n",
      "4328 7\n",
      "4328 18\n",
      "4330 14\n",
      "4331 25\n",
      "4332 11\n",
      "4333 21\n",
      "4334 1\n",
      "4335 15\n",
      "4338 14\n",
      "4340 0\n",
      "4341 26\n",
      "4341 28\n",
      "4343 21\n",
      "4347 19\n",
      "4351 2\n",
      "4354 3\n",
      "4355 10\n",
      "4355 24\n",
      "4356 10\n",
      "4357 3\n",
      "4360 19\n",
      "4361 23\n",
      "4362 15\n",
      "4363 2\n",
      "4370 4\n",
      "4371 4\n",
      "4375 20\n",
      "4376 3\n",
      "4376 7\n",
      "4382 10\n",
      "4384 2\n",
      "4384 7\n",
      "4384 10\n",
      "4385 9\n",
      "4387 23\n",
      "4392 20\n",
      "4393 0\n",
      "4393 3\n",
      "4394 24\n",
      "4396 2\n",
      "4396 3\n",
      "4397 0\n",
      "4397 5\n",
      "4399 34\n",
      "4399 48\n",
      "4399 51\n",
      "4400 0\n",
      "4408 0\n",
      "4412 7\n",
      "4415 26\n",
      "4416 10\n",
      "4419 0\n",
      "4420 35\n",
      "4421 14\n",
      "4422 12\n",
      "4423 15\n",
      "4423 17\n",
      "4425 34\n",
      "4428 18\n",
      "4428 28\n",
      "4432 0\n",
      "4432 6\n",
      "4433 3\n",
      "4440 13\n",
      "4442 0\n",
      "4444 3\n",
      "4451 0\n",
      "4451 25\n",
      "4457 10\n",
      "4459 0\n",
      "4459 7\n",
      "4461 14\n",
      "4461 44\n",
      "4462 1\n",
      "4462 17\n",
      "4463 1\n",
      "4464 6\n",
      "4465 0\n",
      "4472 1\n",
      "4476 6\n",
      "4477 14\n",
      "4479 1\n",
      "4481 10\n",
      "4484 3\n",
      "4484 13\n",
      "4485 5\n",
      "4486 1\n",
      "4486 2\n",
      "4493 1\n",
      "4495 3\n",
      "4496 13\n",
      "4498 11\n",
      "4505 5\n",
      "4507 5\n",
      "4508 0\n",
      "4510 13\n",
      "4516 0\n",
      "4516 8\n",
      "4517 4\n",
      "4518 4\n",
      "4518 16\n",
      "4519 17\n",
      "4521 0\n",
      "4524 5\n",
      "4526 28\n",
      "4527 0\n",
      "4528 11\n",
      "4529 23\n",
      "4533 1\n",
      "4533 20\n",
      "4534 17\n",
      "4535 25\n",
      "4535 31\n",
      "4536 9\n",
      "4538 1\n",
      "4538 10\n",
      "4540 28\n",
      "4540 30\n",
      "4540 35\n",
      "4542 4\n",
      "4543 13\n",
      "4543 38\n",
      "4544 9\n",
      "4544 11\n",
      "4544 15\n",
      "4544 20\n",
      "4545 3\n",
      "4545 4\n",
      "4545 16\n",
      "4546 12\n",
      "4546 14\n",
      "4546 38\n",
      "4547 41\n",
      "4550 15\n",
      "4551 10\n",
      "4558 8\n",
      "4558 9\n",
      "4558 11\n",
      "4559 10\n",
      "4560 9\n",
      "4561 5\n",
      "4562 5\n",
      "4562 14\n",
      "4563 16\n",
      "4567 11\n",
      "4567 19\n",
      "4567 21\n",
      "4569 2\n",
      "4569 5\n",
      "4570 4\n",
      "4571 0\n",
      "4571 1\n",
      "4571 3\n",
      "4572 10\n",
      "4572 12\n",
      "4573 17\n",
      "4575 7\n",
      "4575 13\n",
      "4576 0\n",
      "4577 0\n",
      "4578 12\n",
      "4578 29\n",
      "4579 2\n",
      "4580 8\n",
      "4580 15\n",
      "4580 18\n",
      "4581 16\n",
      "4582 0\n",
      "4584 27\n",
      "4593 18\n",
      "4597 12\n",
      "4600 3\n",
      "4611 3\n",
      "4613 4\n",
      "4614 2\n",
      "4614 23\n",
      "4615 24\n",
      "4617 13\n",
      "4619 20\n",
      "4629 0\n",
      "4632 15\n",
      "4640 3\n",
      "4641 0\n",
      "4643 16\n",
      "4644 0\n",
      "4648 0\n",
      "4648 11\n",
      "4649 17\n",
      "4652 4\n",
      "4653 16\n",
      "4654 5\n",
      "4657 3\n",
      "4657 6\n",
      "4660 3\n",
      "4667 9\n",
      "4670 5\n",
      "4674 18\n",
      "4676 8\n",
      "4676 38\n",
      "4677 8\n",
      "4677 21\n",
      "4677 27\n",
      "4678 11\n",
      "4680 1\n",
      "4681 0\n",
      "4681 6\n",
      "4682 8\n",
      "4682 10\n",
      "4683 18\n",
      "4683 19\n",
      "4686 22\n",
      "4688 0\n",
      "4689 17\n",
      "4690 11\n",
      "4690 19\n",
      "4692 1\n",
      "4693 17\n",
      "4693 18\n",
      "4695 9\n",
      "4695 11\n",
      "4699 0\n",
      "4699 9\n",
      "4703 8\n",
      "4706 0\n",
      "4707 0\n",
      "4709 0\n",
      "4709 2\n",
      "4712 7\n",
      "4712 15\n",
      "4714 8\n",
      "4714 9\n",
      "4723 0\n",
      "4724 8\n",
      "4724 10\n",
      "4725 9\n",
      "4726 25\n",
      "4727 9\n",
      "4730 13\n",
      "4736 30\n",
      "4739 0\n",
      "4739 4\n",
      "4742 42\n",
      "4744 5\n",
      "4746 17\n",
      "4747 8\n",
      "4748 11\n",
      "4750 21\n",
      "4755 0\n",
      "4755 4\n",
      "4755 13\n",
      "4757 3\n",
      "4758 3\n",
      "4759 0\n",
      "4759 10\n",
      "4760 12\n",
      "4761 1\n",
      "4761 4\n",
      "4761 14\n",
      "4761 23\n",
      "4761 32\n",
      "4761 34\n",
      "4762 0\n",
      "4762 8\n",
      "4763 16\n",
      "4764 20\n",
      "4766 37\n",
      "4768 25\n",
      "4769 0\n",
      "4775 8\n",
      "4780 2\n",
      "4781 2\n",
      "4782 24\n",
      "4782 25\n",
      "4787 18\n",
      "4788 14\n",
      "4789 1\n",
      "4789 18\n",
      "4789 22\n",
      "4790 7\n",
      "4790 9\n",
      "4791 0\n",
      "4792 9\n",
      "4792 12\n",
      "4793 4\n",
      "4798 7\n",
      "4799 8\n",
      "4800 0\n",
      "4800 2\n",
      "4803 2\n",
      "4806 8\n",
      "4807 24\n",
      "4809 3\n",
      "4812 14\n",
      "4814 25\n",
      "4816 27\n",
      "4821 10\n",
      "4821 19\n",
      "4822 1\n",
      "4822 3\n",
      "4823 8\n",
      "4823 18\n",
      "4824 9\n",
      "4825 26\n",
      "4827 16\n",
      "4827 28\n",
      "4828 2\n",
      "4829 11\n",
      "4830 8\n",
      "4831 9\n",
      "4835 12\n",
      "4837 10\n",
      "4840 25\n",
      "4841 3\n",
      "4844 13\n",
      "4847 9\n",
      "4847 34\n",
      "4849 6\n",
      "4850 0\n",
      "4851 0\n",
      "4851 18\n",
      "4851 32\n",
      "4852 9\n",
      "4852 14\n",
      "4854 9\n",
      "4854 18\n",
      "4856 4\n",
      "4856 14\n",
      "4859 2\n",
      "4861 16\n",
      "4862 18\n",
      "4864 3\n",
      "4867 56\n",
      "4877 9\n",
      "4881 15\n",
      "4883 22\n",
      "4883 44\n",
      "4885 42\n",
      "4886 31\n",
      "4890 3\n",
      "4891 16\n",
      "4895 0\n",
      "4895 2\n",
      "4896 10\n",
      "4896 22\n",
      "4897 12\n",
      "4899 6\n",
      "4899 9\n",
      "4899 15\n",
      "4899 20\n",
      "4901 7\n",
      "4901 24\n",
      "4903 2\n",
      "4905 11\n",
      "4907 13\n",
      "4910 17\n",
      "4913 0\n",
      "4913 2\n",
      "4916 5\n",
      "4918 1\n",
      "4918 3\n",
      "4918 25\n",
      "4918 28\n",
      "4920 0\n",
      "4921 17\n",
      "4922 5\n",
      "4926 12\n",
      "4930 15\n",
      "4933 5\n",
      "4933 11\n",
      "4934 1\n",
      "4935 0\n",
      "4935 3\n",
      "4937 8\n",
      "4939 2\n",
      "4942 4\n",
      "4944 1\n",
      "4945 2\n",
      "4947 2\n",
      "4948 2\n",
      "4948 13\n",
      "4949 8\n",
      "4950 13\n",
      "4952 6\n",
      "4952 13\n",
      "4952 21\n",
      "4953 11\n",
      "4953 12\n",
      "4955 13\n",
      "4957 4\n",
      "4957 8\n",
      "4958 2\n",
      "4960 5\n",
      "4960 17\n",
      "4960 21\n",
      "4961 22\n",
      "4963 23\n",
      "4964 29\n",
      "4965 6\n",
      "4965 14\n",
      "4966 5\n",
      "4967 7\n",
      "4967 19\n",
      "4968 10\n",
      "4969 4\n",
      "4970 23\n",
      "4973 19\n",
      "4975 2\n",
      "4978 0\n",
      "4979 6\n",
      "4980 0\n",
      "4980 23\n",
      "4981 19\n",
      "4982 5\n",
      "4983 3\n",
      "4984 12\n",
      "4990 6\n",
      "4990 20\n",
      "4993 6\n",
      "4996 10\n",
      "4999 15\n",
      "5004 6\n",
      "5009 24\n",
      "5010 7\n",
      "5011 9\n",
      "5014 8\n",
      "5014 24\n",
      "5015 10\n",
      "5015 13\n",
      "5016 2\n",
      "5017 20\n",
      "5019 6\n",
      "5019 19\n",
      "5019 21\n",
      "5021 7\n",
      "5021 10\n",
      "5022 6\n",
      "5022 11\n",
      "5022 29\n",
      "5023 12\n",
      "5023 18\n",
      "5025 0\n",
      "5027 18\n",
      "5029 4\n",
      "5030 16\n",
      "5031 8\n",
      "5031 9\n",
      "5032 6\n",
      "5033 7\n",
      "5034 8\n",
      "5038 0\n",
      "5038 8\n",
      "5038 17\n",
      "5039 9\n",
      "5039 13\n",
      "5040 0\n",
      "5040 20\n",
      "5041 5\n",
      "5041 14\n",
      "5042 2\n",
      "5042 17\n",
      "5043 19\n",
      "5047 18\n",
      "5048 16\n",
      "5048 18\n",
      "5050 2\n",
      "5050 10\n",
      "5051 2\n",
      "5054 9\n",
      "5055 12\n",
      "5057 25\n",
      "5057 27\n",
      "5059 9\n",
      "5059 15\n",
      "5060 8\n",
      "5061 34\n",
      "5063 3\n",
      "5063 12\n",
      "5063 13\n",
      "5064 9\n",
      "5067 9\n",
      "5068 15\n",
      "5068 17\n",
      "5070 0\n",
      "5071 12\n",
      "5073 7\n",
      "5076 9\n",
      "5078 0\n",
      "5078 10\n",
      "5092 1\n",
      "5092 4\n",
      "5092 5\n",
      "5094 4\n",
      "5097 15\n",
      "5098 18\n",
      "5098 21\n",
      "5099 2\n",
      "5100 9\n",
      "5106 2\n",
      "5108 0\n",
      "5110 19\n",
      "5111 0\n",
      "5114 6\n",
      "5116 16\n",
      "5119 10\n",
      "5119 12\n",
      "5119 13\n",
      "5119 15\n",
      "5119 24\n",
      "5121 3\n",
      "5122 13\n",
      "5123 7\n",
      "5124 4\n",
      "5125 5\n",
      "5126 5\n",
      "5126 9\n",
      "5129 8\n",
      "5130 14\n",
      "5130 20\n",
      "5131 8\n",
      "5133 20\n",
      "5134 4\n",
      "5134 24\n",
      "5135 32\n",
      "5136 0\n",
      "5136 3\n",
      "5137 10\n",
      "5137 21\n",
      "5138 7\n",
      "5138 9\n",
      "5138 11\n",
      "5139 0\n",
      "5139 13\n",
      "5139 26\n",
      "5140 17\n",
      "5141 24\n",
      "5142 2\n",
      "5142 24\n",
      "5143 3\n",
      "5144 17\n",
      "5144 18\n",
      "5145 0\n",
      "5145 7\n",
      "5148 15\n",
      "5149 4\n",
      "5151 6\n",
      "5152 1\n",
      "5153 7\n",
      "5153 14\n",
      "5153 16\n",
      "5154 6\n",
      "5156 9\n",
      "5157 3\n",
      "5157 7\n",
      "5157 9\n",
      "5158 16\n",
      "5159 15\n",
      "5164 4\n",
      "5164 8\n",
      "5164 16\n",
      "5165 22\n",
      "5165 26\n",
      "5166 5\n",
      "5168 0\n",
      "5171 4\n",
      "5173 10\n",
      "5173 26\n",
      "5173 30\n",
      "5174 24\n",
      "5175 5\n",
      "5176 4\n",
      "5176 7\n",
      "5179 10\n",
      "5179 11\n",
      "5181 21\n",
      "5182 10\n",
      "5182 15\n",
      "5183 3\n",
      "5185 6\n",
      "5186 0\n",
      "5187 0\n",
      "5188 25\n",
      "5189 9\n",
      "5192 15\n",
      "5193 23\n",
      "5194 0\n",
      "5198 0\n",
      "5198 4\n",
      "5198 20\n",
      "5200 11\n",
      "5202 17\n",
      "5204 5\n",
      "5206 19\n",
      "5207 3\n",
      "5208 0\n",
      "5208 14\n",
      "5208 17\n",
      "5209 3\n",
      "5209 7\n",
      "5210 12\n",
      "5212 19\n",
      "5213 12\n",
      "5213 14\n",
      "5214 3\n",
      "5214 10\n",
      "5215 8\n",
      "5215 17\n",
      "5216 1\n",
      "5217 13\n",
      "5217 18\n",
      "5219 8\n",
      "5219 13\n",
      "5219 20\n",
      "5220 3\n",
      "5224 12\n",
      "5224 14\n",
      "5225 7\n",
      "5226 7\n",
      "5226 10\n",
      "5227 0\n",
      "5227 21\n",
      "5227 22\n",
      "5230 6\n",
      "5231 0\n",
      "5232 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5232 18\n",
      "5232 21\n",
      "5233 12\n",
      "5233 16\n",
      "5233 33\n",
      "5234 3\n",
      "5234 17\n",
      "5234 32\n",
      "5235 8\n",
      "5235 11\n",
      "5235 14\n",
      "5237 18\n",
      "5240 12\n",
      "5243 18\n",
      "5244 1\n",
      "5244 2\n",
      "5244 11\n",
      "5245 14\n",
      "5245 17\n",
      "5247 3\n",
      "5247 5\n",
      "5248 11\n",
      "5248 19\n",
      "5249 0\n",
      "5249 9\n",
      "5249 11\n",
      "5250 20\n",
      "5251 19\n",
      "5252 0\n",
      "5252 9\n",
      "5254 11\n",
      "5255 14\n",
      "5257 18\n",
      "5258 0\n",
      "5258 9\n",
      "5259 10\n",
      "5260 1\n",
      "5261 27\n",
      "5261 30\n",
      "5262 0\n",
      "5262 2\n",
      "5262 8\n",
      "5264 8\n",
      "5265 9\n",
      "5266 12\n",
      "5266 20\n",
      "5267 14\n",
      "5268 6\n",
      "5271 16\n",
      "5274 2\n",
      "5274 6\n",
      "5276 12\n",
      "5277 17\n",
      "5278 15\n",
      "5280 1\n",
      "5283 9\n",
      "5285 23\n",
      "5286 1\n",
      "5286 24\n",
      "5288 4\n",
      "5288 5\n",
      "5289 0\n",
      "5290 4\n",
      "5290 9\n",
      "5290 21\n",
      "5291 8\n",
      "5291 17\n",
      "5292 2\n",
      "5292 12\n",
      "5292 14\n",
      "5292 16\n",
      "5292 23\n",
      "5293 6\n",
      "5293 13\n",
      "5293 14\n",
      "5294 5\n",
      "5296 28\n",
      "5297 25\n",
      "5300 0\n",
      "5301 23\n",
      "5302 0\n",
      "5306 17\n",
      "5307 23\n",
      "5308 34\n",
      "5312 10\n",
      "5312 21\n",
      "5312 23\n",
      "5314 25\n",
      "5315 6\n",
      "5315 8\n",
      "5316 34\n",
      "5317 12\n",
      "5318 0\n",
      "5318 5\n",
      "5318 6\n",
      "5318 24\n",
      "5318 26\n",
      "5319 22\n",
      "5319 24\n",
      "5320 7\n",
      "5320 10\n",
      "5320 18\n",
      "5321 10\n",
      "5323 0\n",
      "5324 1\n",
      "5325 14\n",
      "5325 23\n",
      "5328 8\n",
      "5329 4\n",
      "5331 14\n",
      "5332 25\n",
      "5333 10\n",
      "5334 3\n",
      "5334 7\n",
      "5334 9\n",
      "5335 7\n",
      "5335 9\n",
      "5337 1\n",
      "5337 13\n",
      "5338 7\n",
      "5339 18\n",
      "5340 21\n",
      "5341 21\n",
      "5344 17\n",
      "5345 13\n",
      "5351 9\n",
      "5352 8\n",
      "5353 0\n",
      "5355 3\n",
      "5355 8\n",
      "5357 25\n",
      "5358 7\n",
      "5358 26\n",
      "5362 33\n",
      "5364 5\n",
      "5364 13\n",
      "5366 0\n",
      "5366 8\n",
      "5369 10\n",
      "5369 19\n",
      "5372 0\n",
      "5372 3\n",
      "5372 9\n",
      "5372 13\n",
      "5372 20\n",
      "5374 4\n",
      "5374 7\n",
      "5374 9\n",
      "5377 19\n",
      "5378 0\n",
      "5380 1\n",
      "5380 11\n",
      "5380 13\n",
      "5381 3\n",
      "5381 5\n",
      "5381 13\n",
      "5381 18\n",
      "5383 26\n",
      "5384 8\n",
      "5385 19\n",
      "5387 5\n",
      "5387 30\n",
      "5391 0\n",
      "5392 14\n",
      "5392 26\n",
      "5392 28\n",
      "5393 7\n",
      "5396 0\n",
      "5397 2\n",
      "5398 10\n",
      "5398 11\n",
      "5400 3\n",
      "5400 17\n",
      "5401 0\n",
      "5402 2\n",
      "5402 6\n",
      "5406 3\n",
      "5411 7\n",
      "5412 0\n",
      "5413 0\n",
      "5413 15\n",
      "5414 0\n",
      "5415 23\n",
      "5416 5\n",
      "5416 8\n",
      "5417 15\n",
      "5418 24\n",
      "5420 0\n",
      "5423 15\n",
      "5423 24\n",
      "5425 3\n",
      "5427 0\n",
      "5427 19\n",
      "5429 33\n",
      "5433 0\n",
      "5433 14\n",
      "5433 18\n",
      "5435 0\n",
      "5435 16\n",
      "5436 1\n",
      "5436 6\n",
      "5438 11\n",
      "5441 0\n",
      "5441 2\n",
      "5442 18\n",
      "5444 0\n",
      "5444 10\n",
      "5444 11\n",
      "5444 20\n",
      "5445 6\n",
      "5446 5\n",
      "5446 7\n",
      "5446 9\n",
      "5446 16\n",
      "5448 8\n",
      "5448 11\n",
      "5449 2\n",
      "5449 9\n",
      "5449 14\n",
      "5451 0\n",
      "5451 4\n",
      "5451 13\n",
      "5451 16\n",
      "5451 18\n",
      "5451 20\n",
      "5451 22\n",
      "5452 0\n",
      "5453 16\n",
      "5454 10\n",
      "5457 21\n",
      "5460 3\n",
      "5462 8\n",
      "5462 16\n",
      "5464 20\n",
      "5465 14\n",
      "5467 10\n",
      "5468 7\n",
      "5468 14\n",
      "5470 2\n",
      "5470 5\n",
      "5473 14\n",
      "5474 3\n",
      "5476 7\n",
      "5479 0\n",
      "5481 7\n",
      "5482 6\n",
      "5482 9\n",
      "5483 0\n",
      "5484 10\n",
      "5486 0\n",
      "5486 3\n",
      "5487 4\n",
      "5487 10\n",
      "5491 12\n",
      "5498 5\n",
      "5498 32\n",
      "5498 34\n",
      "5502 14\n",
      "5505 10\n",
      "5505 13\n",
      "5506 36\n",
      "5506 41\n",
      "5507 11\n",
      "5507 12\n",
      "5509 6\n",
      "5513 9\n",
      "5515 9\n",
      "5517 23\n",
      "5518 12\n",
      "5519 5\n",
      "5522 0\n",
      "5523 10\n",
      "5530 14\n",
      "5531 6\n",
      "5534 10\n",
      "5535 9\n",
      "5538 0\n",
      "5539 4\n",
      "5542 0\n",
      "5545 13\n",
      "5546 16\n",
      "5549 9\n",
      "5549 22\n",
      "5551 0\n",
      "5554 0\n",
      "5557 8\n",
      "5561 28\n",
      "5565 3\n",
      "5565 5\n",
      "5566 0\n",
      "5566 6\n",
      "5566 18\n",
      "5567 14\n",
      "5571 15\n",
      "5571 32\n",
      "5571 33\n",
      "5574 8\n",
      "5575 26\n",
      "5575 36\n",
      "5576 12\n",
      "5577 25\n",
      "5577 35\n",
      "5578 3\n",
      "5579 15\n",
      "5581 4\n",
      "5583 13\n",
      "5585 7\n",
      "5586 7\n",
      "5587 8\n",
      "5588 10\n",
      "5591 9\n",
      "5593 18\n",
      "5593 22\n",
      "5593 26\n",
      "5594 0\n",
      "5594 5\n",
      "5595 6\n",
      "5597 3\n",
      "5599 2\n",
      "5600 16\n",
      "5600 23\n",
      "5601 6\n",
      "5603 16\n",
      "5603 21\n",
      "5604 6\n",
      "5605 14\n",
      "5606 4\n",
      "5606 28\n",
      "5609 0\n",
      "5609 6\n",
      "5609 10\n",
      "5610 2\n",
      "5611 2\n",
      "5611 9\n",
      "5611 19\n",
      "5611 27\n",
      "5611 28\n",
      "5611 32\n",
      "5612 6\n",
      "5612 14\n",
      "5612 20\n",
      "5613 20\n",
      "5614 29\n",
      "5614 31\n",
      "5614 37\n",
      "5615 7\n",
      "5615 12\n",
      "5617 11\n",
      "5617 37\n",
      "5618 11\n",
      "5620 3\n",
      "5620 9\n",
      "5620 13\n",
      "5620 24\n",
      "5626 0\n",
      "5627 0\n",
      "5634 0\n",
      "5635 14\n",
      "5637 0\n",
      "5637 11\n",
      "5638 14\n"
     ]
    }
   ],
   "source": [
    "for i,sent_emb in enumerate(train_emb):\n",
    "    for j,word_emb in enumerate(sent_emb):\n",
    "        try:\n",
    "            if len(word_emb) != 768:\n",
    "                print(i, j, len(word_emb))\n",
    "        except:\n",
    "            print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_labels(token_list):\n",
    "    sent_labels, sentences, sent_start = [], [], 0\n",
    "    for i, line in enumerate(token_list):\n",
    "        if line == '\\n':\n",
    "            sentences.append(sent_labels)\n",
    "            sent_labels = []\n",
    "        else:        \n",
    "            token, label = line.rstrip().split()\n",
    "            sent_labels.append(label)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "train = open('../data/SG2017_claim/train.txt').readlines()\n",
    "train_labels = get_sent_labels(train)\n",
    "\n",
    "test = open('../data/SG2017_claim/test.txt').readlines()\n",
    "test_labels = get_sent_labels(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sent2features(sent_emb):\n",
    "    features = []\n",
    "\n",
    "    for word_emb in sent_emb:\n",
    "        word_features = {}\n",
    "        if len(word_emb.shape) > 0:\n",
    "            for i in range(word_emb.shape[0]):\n",
    "                word_features['bert_features_{}'.format(i)] = float(word_emb[i])\n",
    "        else:\n",
    "            word_features['bert_features_0'] = float(word_emb)\n",
    "            \n",
    "        features.append(copy.deepcopy(word_features))\n",
    "        del word_features\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "# train_features = [sent2features(sent) for sent in train_emb]\n",
    "# test_features = [sent2features(sent) for sent in test_emb]\n",
    "\n",
    "# pickle.dump(train_features, open('../features/train_claim_emb.p','wb'))\n",
    "# pickle.dump(test_features, open('../features/test_claim_emb.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pickle.load(open('../features/train_claim_emb.p','rb'))\n",
    "test_features = pickle.load(open('../features/test_claim_emb.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talhindi/miniconda3/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.493     0.322     0.389       457\n",
      "     I-claim      0.504     0.408     0.451      5888\n",
      "     O-claim      0.846     0.893     0.869     23083\n",
      "\n",
      "    accuracy                          0.787     29428\n",
      "   macro avg      0.614     0.541     0.570     29428\n",
      "weighted avg      0.772     0.787     0.778     29428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(test_features)\n",
    "# print('Macro F1: ', metrics.flat_f1_score(test_labels, y_pred, average='macro', labels=['0.0','1.0','2.0']))\n",
    "\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(crf, open('../features/crf_bert_emb.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3]\n",
    "x.pop()\n",
    "x.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT + all other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_features(bert_features, other_features):\n",
    "    \n",
    "    for sent_emb_features, sent_other_features in zip(bert_features, other_features):\n",
    "        \n",
    "        for word_emb_features, word_other_features in zip(sent_emb_features[:len(sent_other_features)], sent_other_features):\n",
    "            word_other_features.update(word_emb_features)\n",
    "        \n",
    "        if len(sent_other_features) > len(sent_emb_features):\n",
    "            for _ in range(len(sent_other_features)-len(sent_emb_features)):\n",
    "                sent_other_features.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_other = pickle.load(open('../features/train_all.p','rb'))\n",
    "test_features_other = pickle.load(open('../features/test_all.p','rb'))\n",
    "\n",
    "merge_features(train_features, train_features_other)\n",
    "merge_features(test_features, test_features_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talhindi/miniconda3/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(train_features_other, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.551     0.440     0.489       457\n",
      "     I-claim      0.561     0.485     0.520      5888\n",
      "     O-claim      0.864     0.897     0.880     23083\n",
      "\n",
      "    accuracy                          0.807     29428\n",
      "   macro avg      0.658     0.607     0.630     29428\n",
      "weighted avg      0.798     0.807     0.802     29428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(test_features_other)\n",
    "\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_emb1 = np.load('../features/wm1_claim_emb_0-319.bert.npy', allow_pickle=True)\n",
    "wm_emb2 = np.load('../features/wm1_claim_emb_320-545.bert.npy', allow_pickle=True)\n",
    "wm_emb3 = np.load('../features/wm1_claim_emb_546-end.bert.npy', allow_pickle=True)\n",
    "wm_emb = list(wm_emb1) + list(wm_emb2) + list(wm_emb3)\n",
    "\n",
    "# wm_features = [sent2features(sent) for sent in wm_emb]\n",
    "# pickle.dump(wm_features, open('../features/wm1_emb.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = open('../../data_wm/arg_clean_45_1/test.txt','r').readlines()\n",
    "wm_labels = get_sent_labels(wm)\n",
    "\n",
    "wm_features = pickle.load(open('../features/wm1_emb.p','rb'))\n",
    "len(wm_features), len(wm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.514     0.078     0.135       707\n",
      "     I-claim      0.581     0.144     0.230      7407\n",
      "     O-claim      0.698     0.954     0.806     16841\n",
      "\n",
      "    accuracy                          0.689     24955\n",
      "   macro avg      0.598     0.392     0.391     24955\n",
      "weighted avg      0.658     0.689     0.616     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = pickle.load(open('../features/crf_bert_emb.p','rb'))\n",
    "y_pred = crf.predict(wm_features)\n",
    "# print('Macro F1: ', metrics.flat_f1_score(test_labels, y_pred, average='macro', labels=['0.0','1.0','2.0']))\n",
    "\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_features_other = pickle.load(open('../features/wm_all.p','rb'))\n",
    "merge_features(wm_features, wm_features_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.514     0.027     0.051       707\n",
      "     I-claim      0.632     0.051     0.095      7407\n",
      "     O-claim      0.683     0.987     0.808     16841\n",
      "\n",
      "    accuracy                          0.682     24955\n",
      "   macro avg      0.610     0.355     0.318     24955\n",
      "weighted avg      0.663     0.682     0.575     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(wm_features_other)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 2485)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "count, max_no_claim_sent = 0, 790\n",
    "train_features, train_labels = shuffle(train_features, train_labels, random_state=0)\n",
    "\n",
    "train_features_ds, train_labels_ds = [], []\n",
    "for features, labels in zip(train_features, train_labels):\n",
    "    if all([label == 'O-claim' for label in labels]):\n",
    "        if count < max_no_claim_sent:\n",
    "            train_features_ds.append(features)\n",
    "            train_labels_ds.append(labels)\n",
    "        count += 1\n",
    "    else:\n",
    "        train_features_ds.append(features)\n",
    "        train_labels_ds.append(labels)\n",
    "    \n",
    "len(train_features_ds), len(train_labels_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'O-claim': 27203, 'B-claim': 1800, 'I-claim': 25126}),\n",
       " Counter({'O-claim': 91277, 'B-claim': 1800, 'I-claim': 25126}))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([label for labels in train_labels_ds for label in labels]),Counter([label for labels in train_labels for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talhindi/miniconda3/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(train_features_ds, train_labels_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf_old = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf_old.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.493     0.322     0.389       457\n",
      "     I-claim      0.504     0.408     0.451      5888\n",
      "     O-claim      0.846     0.893     0.869     23083\n",
      "\n",
      "    accuracy                          0.787     29428\n",
      "   macro avg      0.614     0.541     0.570     29428\n",
      "weighted avg      0.772     0.787     0.778     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.368     0.586     0.452       457\n",
      "     I-claim      0.387     0.694     0.497      5888\n",
      "     O-claim      0.894     0.703     0.787     23083\n",
      "\n",
      "    accuracy                          0.699     29428\n",
      "   macro avg      0.550     0.661     0.579     29428\n",
      "weighted avg      0.784     0.699     0.724     29428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf_old.predict(test_features)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "\n",
    "y_pred = crf.predict(test_features)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.514     0.078     0.135       707\n",
      "     I-claim      0.581     0.144     0.230      7407\n",
      "     O-claim      0.698     0.954     0.806     16841\n",
      "\n",
      "    accuracy                          0.689     24955\n",
      "   macro avg      0.598     0.392     0.391     24955\n",
      "weighted avg      0.658     0.689     0.616     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.425     0.223     0.293       707\n",
      "     I-claim      0.535     0.391     0.451      7407\n",
      "     O-claim      0.743     0.846     0.791     16841\n",
      "\n",
      "    accuracy                          0.693     24955\n",
      "   macro avg      0.568     0.487     0.512     24955\n",
      "weighted avg      0.672     0.693     0.676     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf_old.predict(wm_features)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_features)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1\n",
      "Training Model 2\n",
      "Testing on SG\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.386     0.258     0.309       457\n",
      "     I-claim      0.452     0.322     0.376      5888\n",
      "     O-claim      0.828     0.894     0.860     23083\n",
      "\n",
      "    accuracy                          0.770     29428\n",
      "   macro avg      0.555     0.491     0.515     29428\n",
      "weighted avg      0.746     0.770     0.754     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.342     0.573     0.428       457\n",
      "     I-claim      0.353     0.669     0.462      5888\n",
      "     O-claim      0.881     0.668     0.760     23083\n",
      "\n",
      "    accuracy                          0.667     29428\n",
      "   macro avg      0.525     0.637     0.550     29428\n",
      "weighted avg      0.767     0.667     0.695     29428\n",
      "\n",
      "Testing on WM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.528     0.054     0.098       707\n",
      "     I-claim      0.668     0.083     0.148      7407\n",
      "     O-claim      0.690     0.981     0.810     16841\n",
      "\n",
      "    accuracy                          0.688     24955\n",
      "   macro avg      0.629     0.373     0.352     24955\n",
      "weighted avg      0.679     0.688     0.593     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.424     0.192     0.265       707\n",
      "     I-claim      0.450     0.338     0.386      7407\n",
      "     O-claim      0.718     0.813     0.763     16841\n",
      "\n",
      "    accuracy                          0.654     24955\n",
      "   macro avg      0.530     0.448     0.471     24955\n",
      "weighted avg      0.630     0.654     0.637     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count, max_no_claim_sent = 0, 790\n",
    "train_features, train_labels = shuffle(train_features, train_labels, random_state=0)\n",
    "\n",
    "train_features_ds, train_labels_ds = [], []\n",
    "for features, labels in zip(train_features, train_labels):\n",
    "    if all([label == 'O-claim' for label in labels]):\n",
    "        if count < max_no_claim_sent:\n",
    "            train_features_ds.append(features)\n",
    "            train_labels_ds.append(labels)\n",
    "        count += 1\n",
    "    else:\n",
    "        train_features_ds.append(features)\n",
    "        train_labels_ds.append(labels)\n",
    "\n",
    "print('Training Model 1')        \n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(train_features_ds, train_labels_ds)\n",
    "print('Training Model 2')\n",
    "crf_old = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf_old.fit(train_features, train_labels)\n",
    "\n",
    "print('Testing on SG')\n",
    "y_pred = crf_old.predict(test_features)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "\n",
    "y_pred = crf.predict(test_features)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "print('Testing on WM')\n",
    "y_pred = crf_old.predict(wm_features)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_features)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT emb + LexSyn Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lexsyn = pickle.load(open('../features/train_lexsyn.p','rb'))\n",
    "test_lexsyn = pickle.load(open('../features/test_lexsyn.p','rb'))\n",
    "wm_lexsyn = pickle.load(open('../features/wm_lexsyn.p','rb'))\n",
    "\n",
    "merge_features(train_features, train_lexsyn)\n",
    "merge_features(test_features, test_lexsyn)\n",
    "merge_features(wm_features, wm_lexsyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talhindi/miniconda3/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(train_lexsyn, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.525     0.416     0.464       457\n",
      "     I-claim      0.552     0.461     0.503      5888\n",
      "     O-claim      0.859     0.898     0.878     23083\n",
      "\n",
      "    accuracy                          0.804     29428\n",
      "   macro avg      0.645     0.592     0.615     29428\n",
      "weighted avg      0.792     0.804     0.797     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.591     0.110     0.186       707\n",
      "     I-claim      0.658     0.165     0.264      7407\n",
      "     O-claim      0.705     0.962     0.814     16841\n",
      "\n",
      "    accuracy                          0.701     24955\n",
      "   macro avg      0.652     0.413     0.421     24955\n",
      "weighted avg      0.688     0.701     0.633     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(test_lexsyn)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2485, 2485, 2485, 2485)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count, max_no_claim_sent = 0, 790\n",
    "train_features, train_features_other, train_lexsyn, train_labels = shuffle(train_features, train_features_other, train_lexsyn, train_labels, random_state=0)\n",
    "\n",
    "train_features_ds, train_features_other_ds, train_lexsyn_ds, train_labels_ds = [], [], [], []\n",
    "for features, features_other, features_lexsyn, labels in zip(train_features, train_features_other, train_lexsyn, train_labels):\n",
    "    if all([label == 'O-claim' for label in labels]):\n",
    "        if count < max_no_claim_sent:\n",
    "            train_features_ds.append(features)\n",
    "            train_features_other_ds.append(features_other)\n",
    "            train_lexsyn_ds.append(features_lexsyn)\n",
    "            train_labels_ds.append(labels)\n",
    "        count += 1\n",
    "    else:\n",
    "        train_features_ds.append(features)\n",
    "        train_features_other_ds.append(features_other)\n",
    "        train_lexsyn_ds.append(features_lexsyn)\n",
    "        train_labels_ds.append(labels)\n",
    "    \n",
    "len(train_features_ds), len(train_features_other_ds), len(train_lexsyn_ds), len(train_labels_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talhindi/miniconda3/lib/python3.7/site-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(train_lexsyn_ds, train_labels_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.393     0.685     0.500       457\n",
      "     I-claim      0.396     0.756     0.520      5888\n",
      "     O-claim      0.911     0.687     0.783     23083\n",
      "\n",
      "    accuracy                          0.700     29428\n",
      "   macro avg      0.567     0.709     0.601     29428\n",
      "weighted avg      0.800     0.700     0.726     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.447     0.233     0.307       707\n",
      "     I-claim      0.556     0.414     0.474      7407\n",
      "     O-claim      0.751     0.850     0.797     16841\n",
      "\n",
      "    accuracy                          0.703     24955\n",
      "   macro avg      0.585     0.499     0.526     24955\n",
      "weighted avg      0.684     0.703     0.688     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(test_lexsyn)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on SG and WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_emb2 = np.load('../features/wm2_claim_emb.bert.npy', allow_pickle=True)\n",
    "wm_features2 = [sent2features(sent) for sent in wm_emb2]\n",
    "pickle.dump(wm_features2, open('../features/wm2_emb.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1862, 1862)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm2 = open('../../data_wm/arg_clean_45_2/train.txt','r').readlines()\n",
    "wm2_labels = get_sent_labels(wm2)\n",
    "\n",
    "wm_features2 = pickle.load(open('../features/wm2_emb.p','rb'))\n",
    "len(wm_features2), len(wm2_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm2_lexsyn = pickle.load(open('../features/wm2_lexsyn.p','rb'))\n",
    "merge_features(wm_features2, wm2_lexsyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.473     0.359     0.408       457\n",
      "     I-claim      0.480     0.445     0.462      5888\n",
      "     O-claim      0.851     0.871     0.861     23083\n",
      "\n",
      "    accuracy                          0.778     29428\n",
      "   macro avg      0.601     0.558     0.577     29428\n",
      "weighted avg      0.771     0.778     0.774     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.522     0.181     0.269       707\n",
      "     I-claim      0.622     0.323     0.425      7407\n",
      "     O-claim      0.737     0.913     0.816     16841\n",
      "\n",
      "    accuracy                          0.717     24955\n",
      "   macro avg      0.627     0.472     0.503     24955\n",
      "weighted avg      0.697     0.717     0.684     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training on SG and WM using bert embeddings\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(train_features+wm_features2, train_labels+wm2_labels)\n",
    "\n",
    "y_pred = crf.predict(test_features)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_features)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.265     0.383     0.313       457\n",
      "     I-claim      0.355     0.534     0.426      5888\n",
      "     O-claim      0.853     0.735     0.789     23083\n",
      "\n",
      "    accuracy                          0.689     29428\n",
      "   macro avg      0.491     0.551     0.510     29428\n",
      "weighted avg      0.744     0.689     0.709     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.527     0.291     0.375       707\n",
      "     I-claim      0.662     0.432     0.523      7407\n",
      "     O-claim      0.768     0.900     0.829     16841\n",
      "\n",
      "    accuracy                          0.744     24955\n",
      "   macro avg      0.652     0.541     0.576     24955\n",
      "weighted avg      0.730     0.744     0.725     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training only on WM using bert embeddings\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm_features2, wm2_labels)\n",
    "\n",
    "y_pred = crf.predict(test_features)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_features)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.297     0.455     0.359       457\n",
      "     I-claim      0.356     0.522     0.423      5888\n",
      "     O-claim      0.851     0.740     0.792     23083\n",
      "\n",
      "    accuracy                          0.692     29428\n",
      "   macro avg      0.501     0.573     0.525     29428\n",
      "weighted avg      0.743     0.692     0.711     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.572     0.337     0.424       707\n",
      "     I-claim      0.718     0.478     0.574      7407\n",
      "     O-claim      0.785     0.914     0.845     16841\n",
      "\n",
      "    accuracy                          0.768     24955\n",
      "   macro avg      0.692     0.576     0.614     24955\n",
      "weighted avg      0.759     0.768     0.752     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training only on WM using bert embeddings and lexsyn\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_lexsyn, wm2_labels)\n",
    "\n",
    "y_pred = crf.predict(test_lexsyn)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WM DOWNSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, max_no_claim_sent = 0, 300\n",
    "# wm_features2, wm2_lexsyn, wm2_labels = shuffle(wm_features2, wm2_lexsyn, wm2_labels, random_state=0)\n",
    "\n",
    "wm2_features_ds, wm2_lexsyn_ds, wm2_labels_ds = [], [], []\n",
    "for features, features_lexsyn, labels in zip(wm_features2, wm2_lexsyn, wm2_labels):\n",
    "    if all([label == 'O-claim' for label in labels]):\n",
    "        if count < max_no_claim_sent:\n",
    "            wm2_features_ds.append(features)\n",
    "            wm2_lexsyn_ds.append(features_lexsyn)\n",
    "            wm2_labels_ds.append(labels)\n",
    "        count += 1\n",
    "    else:\n",
    "        wm2_features_ds.append(features)\n",
    "        wm2_lexsyn_ds.append(features_lexsyn)\n",
    "        wm2_labels_ds.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'O-claim': 20326, 'B-claim': 951, 'I-claim': 10263}),\n",
       " Counter({'O-claim': 25332, 'B-claim': 951, 'I-claim': 10263}))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([label for labels in wm2_labels_ds for label in labels]),Counter([label for labels in wm2_labels for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.265     0.403     0.319       457\n",
      "     I-claim      0.339     0.552     0.420      5888\n",
      "     O-claim      0.852     0.707     0.773     23083\n",
      "\n",
      "    accuracy                          0.671     29428\n",
      "   macro avg      0.485     0.554     0.504     29428\n",
      "weighted avg      0.741     0.671     0.695     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.487     0.321     0.387       707\n",
      "     I-claim      0.623     0.485     0.546      7407\n",
      "     O-claim      0.778     0.865     0.819     16841\n",
      "\n",
      "    accuracy                          0.737     24955\n",
      "   macro avg      0.630     0.557     0.584     24955\n",
      "weighted avg      0.724     0.737     0.726     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training only on WM -- downsampled 20% -- bert embeddings only\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_features_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(test_features)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_features)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.237     0.556     0.332       457\n",
      "     I-claim      0.309     0.729     0.434      5888\n",
      "     O-claim      0.883     0.554     0.681     23083\n",
      "\n",
      "    accuracy                          0.589     29428\n",
      "   macro avg      0.476     0.613     0.482     29428\n",
      "weighted avg      0.758     0.589     0.626     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.436     0.450     0.443       707\n",
      "     I-claim      0.553     0.629     0.589      7407\n",
      "     O-claim      0.813     0.762     0.787     16841\n",
      "\n",
      "    accuracy                          0.714     24955\n",
      "   macro avg      0.600     0.614     0.606     24955\n",
      "weighted avg      0.725     0.714     0.718     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training only on WM -- downsampled 72% -- bert embeddings only\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_features_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(test_features)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_features)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.291     0.514     0.372       457\n",
      "     I-claim      0.346     0.578     0.433      5888\n",
      "     O-claim      0.859     0.699     0.771     23083\n",
      "\n",
      "    accuracy                          0.672     29428\n",
      "   macro avg      0.499     0.597     0.525     29428\n",
      "weighted avg      0.748     0.672     0.697     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.552     0.396     0.461       707\n",
      "     I-claim      0.681     0.543     0.604      7407\n",
      "     O-claim      0.801     0.882     0.840     16841\n",
      "\n",
      "    accuracy                          0.768     24955\n",
      "   macro avg      0.678     0.607     0.635     24955\n",
      "weighted avg      0.758     0.768     0.759     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training only on WM -- downsampled 20% -- bert embeddings and lexsyn\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_lexsyn_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(test_lexsyn)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.247     0.624     0.354       457\n",
      "     I-claim      0.318     0.767     0.450      5888\n",
      "     O-claim      0.897     0.547     0.680     23083\n",
      "\n",
      "    accuracy                          0.592     29428\n",
      "   macro avg      0.487     0.646     0.494     29428\n",
      "weighted avg      0.771     0.592     0.628     29428\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.473     0.515     0.493       707\n",
      "     I-claim      0.585     0.683     0.630      7407\n",
      "     O-claim      0.836     0.772     0.803     16841\n",
      "\n",
      "    accuracy                          0.738     24955\n",
      "   macro avg      0.631     0.656     0.642     24955\n",
      "weighted avg      0.751     0.738     0.743     24955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training only on WM -- downsampled 20% -- bert embeddings and lexsyn\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_lexsyn_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(test_lexsyn)\n",
    "y_test_flat = [y for y_seq in test_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WM Narrative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "narr_emb = np.load('../features/narrative.bert.npy', allow_pickle=True)\n",
    "narr_features = [sent2features(sent) for sent in narr_emb]\n",
    "pickle.dump(narr_features, open('../features/narr_emb.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1332, 1332)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narr = open('../../data_wm/wm_narrative/test.txt','r').readlines()\n",
    "narr_labels = get_sent_labels(narr)\n",
    "\n",
    "narr_features = pickle.load(open('../features/narr_emb.p','rb'))\n",
    "len(narr_features), len(narr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.053     0.270     0.089        37\n",
      "     I-claim      0.092     0.426     0.151       350\n",
      "     O-claim      0.989     0.923     0.955     21465\n",
      "\n",
      "    accuracy                          0.914     21852\n",
      "   macro avg      0.378     0.540     0.398     21852\n",
      "weighted avg      0.973     0.914     0.941     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training only on WM -- no downsampling -- bert embeddings only\n",
    "y_pred = crf.predict(narr_features)\n",
    "y_test_flat = [y for y_seq in narr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.040     0.297     0.071        37\n",
      "     I-claim      0.070     0.509     0.123       350\n",
      "     O-claim      0.990     0.878     0.931     21465\n",
      "\n",
      "    accuracy                          0.871     21852\n",
      "   macro avg      0.367     0.561     0.375     21852\n",
      "weighted avg      0.974     0.871     0.916     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training only on WM -- downsampled 20% -- bert embeddings only\n",
    "y_pred = crf.predict(narr_features)\n",
    "y_test_flat = [y for y_seq in narr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training only on WM -- downsampled 80% -- bert embeddings only\n",
    "y_pred = crf.predict(narr_features)\n",
    "y_test_flat = [y for y_seq in narr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narr_lexsyn = pickle.load(open('../features/narr_lexsyn.p','rb'))\n",
    "merge_features(narr_features, narr_lexsyn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
