{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import string\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "import networkx as nx\n",
    "model_dir = '/Users/talhindi/miniconda3/lib/python3.7/site-packages/en_core_web_sm/en_core_web_sm-2.1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = pd.read_csv('../data/SG2017/train-test-split.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_txt_prg_list = []\n",
    "for file in sorted(glob.glob(\"../data/SG2017/*.txt\")):\n",
    "    essay = open(file).readlines()\n",
    "    essays_txt_prg_list.append(essay)\n",
    "\n",
    "essay_txt_str = []\n",
    "for essay in essays_txt_prg_list:\n",
    "    essay_txt_str.append(''.join(essay))\n",
    "    \n",
    "essays_ann = []\n",
    "for file in sorted(glob.glob(\"../data/SG2017/*.ann\")):\n",
    "    essay = open(file).readlines()\n",
    "    essays_ann.append(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_segments = []\n",
    "\n",
    "for essay in essays_ann:    \n",
    "    segments = []\n",
    "    \n",
    "    for line in essay:\n",
    "        if line[0] == 'T':\n",
    "            _, label_s_e, text = line.rstrip().split('\\t')\n",
    "            label, start, end = label_s_e.split()\n",
    "            segments.append((label, int(start), int(end), text))\n",
    "            \n",
    "    segments.sort(key = lambda element : element[1])\n",
    "    essays_segments.append(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(essay_spacy, segments):\n",
    "    '''O = 0, Arg-B = 1, Arg-I = 2'''\n",
    "    \n",
    "    doc_len = len(essay_spacy)\n",
    "    \n",
    "    labels = []\n",
    "    tokens = []\n",
    "    arg_seg_starts = [start for arg_type, start, end, text in segments]\n",
    "    \n",
    "    for token in essay_spacy:\n",
    "        arg_I_token = False\n",
    "\n",
    "        if token.idx in arg_seg_starts:\n",
    "            labels.append('Arg-B')\n",
    "#             labels.append(1.0)\n",
    "            tokens.append(token.text)\n",
    "            assert token.text in segments[arg_seg_starts.index(token.idx)][-1]\n",
    "        else:\n",
    "            for _, start, end, _ in segments:\n",
    "                if token.idx > start and token.idx+len(token) <= end:\n",
    "                    labels.append('Arg-I')\n",
    "#                     labels.append(2.0)\n",
    "                    tokens.append(token.text)\n",
    "                    arg_I_token = True\n",
    "            if not arg_I_token:\n",
    "                labels.append('O')\n",
    "#                 labels.append(0.0)\n",
    "                tokens.append(token.text)\n",
    "\n",
    "    assert len(labels) == doc_len\n",
    "    return tokens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(model_dir)\n",
    "\n",
    "essay_spacy = []\n",
    "for essay in essay_txt_str:\n",
    "    essay_spacy.append(nlp(essay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(int, {0.0: 39617, 1.0: 4823, 2.0: 75312}),\n",
       " defaultdict(int, {0.0: 9801, 1.0: 1266, 2.0: 18748}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting labels from each type\n",
    "# without new lines\n",
    "token_labels = []\n",
    "train_BIO = defaultdict(int)\n",
    "test_BIO = defaultdict(int)\n",
    "\n",
    "for doc, segments, group in zip(essay_spacy, essays_segments, train_test_split.SET):\n",
    "    tokens, labels = get_labels(doc, segments)\n",
    "    \n",
    "    if group == \"TRAIN\":\n",
    "        for label in  labels:\n",
    "            train_BIO[label] += 1\n",
    "    else:\n",
    "        for label in  labels:\n",
    "            test_BIO[label] += 1\n",
    "    \n",
    "train_BIO,test_BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''probability-feature:\n",
    "        is the conditional probability of the current token t_i \n",
    "        being the beginning of an argument component (“Arg-B”) given its preceding tokens (up to 3 prev_tokens).\n",
    "        using MLE on the training data\n",
    "'''\n",
    "def train_vectorizer(essay_spacy, essays_segments, train_test_split, labeling_function, B_labels='Arg-B'):\n",
    "    \n",
    "    argB_train_segments = []\n",
    "    for essay, segments, group in zip(essay_spacy, essays_segments, train_test_split):\n",
    "        tokens, labels = labeling_function(essay, segments)\n",
    "\n",
    "        for i, (t, l)  in enumerate(zip(tokens, labels)):\n",
    "            if l == B_labels:\n",
    "                if group == 'TRAIN':\n",
    "                    argB_train_segments.append(' '.join([tokens[i-3],tokens[i-2],tokens[i-1]]) )\n",
    "        \n",
    "    vect = CountVectorizer(ngram_range=(1,3))\n",
    "    vect.fit(argB_train_segments)\n",
    "        \n",
    "    return vect\n",
    "        \n",
    "\n",
    "def get_probability_features(doc, vectorizer):\n",
    "    \n",
    "    features = []\n",
    "    for i, token in enumerate(doc):\n",
    "        if i == 0:\n",
    "            prev_context = ''\n",
    "        elif i == 1:\n",
    "            prev_context = doc[0].text\n",
    "        elif i == 2:\n",
    "            prev_context = ' '.join([doc[0].text, doc[1].text])\n",
    "        else:\n",
    "            prev_context = ' '.join([doc[i-3].text, doc[i-2].text, doc[i-1].text])\n",
    "            \n",
    "        grams = vectorizer.transform([prev_context])[0]\n",
    "        features.append({'probability_feature': grams.count_nonzero()/ grams.shape[1]})\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = train_vectorizer(essay_spacy, essays_segments, train_test_split.SET, get_labels)\n",
    "open('../features/SG2017_train/probability.jsonlines', 'w')\n",
    "open('../features/SG2017_test/probability.jsonlines', 'w')\n",
    "\n",
    "token_id = 0\n",
    "for i, (doc, segments, group) in enumerate(zip(essay_spacy, essays_segments, train_test_split.SET)):\n",
    "\n",
    "    features = get_probability_features(doc, vectorizer)\n",
    "    tokens, labels = get_labels(doc, segments)\n",
    "\n",
    "    if group == \"TRAIN\":\n",
    "        with open('../features/SG2017_train/probability.jsonlines', 'a') as file:\n",
    "            for f, l in zip(features, labels):\n",
    "                file.write('{{\"y\": {}, \"x\": {}, \"id\": {}}}\\n'.format(l, json.dumps(f), token_id))\n",
    "                token_id +=1\n",
    "    else:\n",
    "        with open('../features/SG2017_test/probability.jsonlines', 'a') as file:\n",
    "            for f, l in zip(features, labels):\n",
    "                file.write('{{\"y\": {}, \"x\": {}, \"id\": {}}}\\n'.format(l, json.dumps(f), token_id))\n",
    "                token_id +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "argB_train_segments, argB_test_segments, other_test_segments, all_segments = [], [], [], []\n",
    "\n",
    "for essay, segments, group in zip(essay_spacy, essays_segments, train_test_split.SET):\n",
    "    tokens, labels = get_labels(essay, segments)\n",
    "    \n",
    "    for i, (t, l)  in enumerate(zip(tokens, labels)):\n",
    "        if l == 'Arg-B':\n",
    "            if group == 'TRAIN':\n",
    "                argB_train_segments.append(' '.join([tokens[i-3],tokens[i-2],tokens[i-1]]) )\n",
    "            else:\n",
    "                argB_test_segments.append(' '.join([tokens[i-3],tokens[i-2],tokens[i-1]]) )\n",
    "#                 argB_test_segments.append([tokens[i-1],\n",
    "#                             ' '.join([tokens[i-2],tokens[i-1]]),\n",
    "#                             ' '.join([tokens[i-3],tokens[i-2],tokens[i-1]])])\n",
    "        else:\n",
    "            if group == 'TEST':\n",
    "                other_test_segments.append(' '.join([tokens[i-3],tokens[i-2],tokens[i-1]]) )\n",
    "#                 other_test_segments.append([tokens[i-1],\n",
    "#                             ' '.join([tokens[i-2],tokens[i-1]]),\n",
    "#                             ' '.join([tokens[i-3],tokens[i-2],tokens[i-1]])]) \n",
    "        \n",
    "        all_segments.append([tokens[i-1],\n",
    "                            ' '.join([tokens[i-2],tokens[i-1]]),\n",
    "                            ' '.join([tokens[i-3],tokens[i-2],tokens[i-1]])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4823x4698 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13942 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,3))\n",
    "vect.fit_transform(argB_train_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({6: 619, 3: 3006, 1: 1195, 5: 3})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_counts = []\n",
    "for vec in train_grams:\n",
    "    vec_counts.append(vec.count_nonzero())\n",
    "\n",
    "Counter(vec_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 357),\n",
       " (2, 286),\n",
       " (3, 242),\n",
       " (1, 128),\n",
       " (10, 71),\n",
       " (7, 56),\n",
       " (0, 48),\n",
       " (8, 28),\n",
       " (5, 22),\n",
       " (6, 21),\n",
       " (9, 7)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argB_test_vec_counts = []\n",
    "for prev_tokens in argB_test_segments:\n",
    "    grams = vect.transform(prev_tokens)\n",
    "    counts = 0\n",
    "    for gram in grams:\n",
    "        counts += gram.count_nonzero()\n",
    "    \n",
    "    argB_test_vec_counts.append(counts)\n",
    "\n",
    "Counter(argB_test_vec_counts).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 6269),\n",
       " (4, 5265),\n",
       " (3, 5250),\n",
       " (5, 3633),\n",
       " (7, 2122),\n",
       " (2, 1824),\n",
       " (1, 1813),\n",
       " (8, 1233),\n",
       " (0, 758),\n",
       " (9, 288),\n",
       " (10, 94)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_test_vec_counts = []\n",
    "for prev_tokens in other_test_segments:\n",
    "    grams = vect.transform(prev_tokens)\n",
    "    counts = 0\n",
    "    for gram in grams:\n",
    "        counts += gram.count_nonzero()\n",
    "    \n",
    "    other_test_vec_counts.append(counts)\n",
    "\n",
    "Counter(other_test_vec_counts).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 448), (3, 374), (2, 284), (6, 71), (0, 48), (4, 34), (5, 7)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argB_test_vec_counts = []\n",
    "for prev_tokens in argB_test_segments:\n",
    "    grams = vect.transform([prev_tokens])[0]\n",
    "    argB_test_vec_counts.append(grams.count_nonzero())\n",
    "\n",
    "Counter(argB_test_vec_counts).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 11425), (3, 7964), (1, 5585), (4, 2435), (0, 758), (5, 288), (6, 94)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_test_vec_counts = []\n",
    "for prev_tokens in other_test_segments:\n",
    "    grams = vect.transform([prev_tokens])[0]\n",
    "    other_test_vec_counts.append(grams.count_nonzero())\n",
    "\n",
    "Counter(other_test_vec_counts).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 32687),\n",
       " (4, 29488),\n",
       " (3, 25094),\n",
       " (5, 18123),\n",
       " (7, 11738),\n",
       " (2, 9744),\n",
       " (1, 8889),\n",
       " (8, 7688),\n",
       " (0, 3358),\n",
       " (9, 1550),\n",
       " (10, 1208)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_vec_counts = []\n",
    "# for prev_tokens in all_segments:\n",
    "#     grams = vect.transform(prev_tokens)\n",
    "#     counts = 0\n",
    "#     for gram in grams:\n",
    "#         counts += gram.count_nonzero()\n",
    "    \n",
    "#     all_vec_counts.append(counts)\n",
    "\n",
    "Counter(all_vec_counts).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mle_train_segments = []\n",
    "argB_segments, other_segments, vocab = [], [], []\n",
    "for essay, segments, group in zip(essay_spacy, essays_segments, train_test_split.SET):\n",
    "    tokens, labels = get_labels(essay, segments)\n",
    "    for i, (t, l)  in enumerate(zip(tokens, labels)):\n",
    "        if l == 'Arg-B':\n",
    "            print('Previous Tokens --> {}:{}  {}:{}  {}:{}'.format(labels[i-3], repr(tokens[i-3]),\n",
    "                                                    labels[i-2], repr(tokens[i-2]), labels[i-1], repr(tokens[i-1])))\n",
    "            print(group,'{}: {}'.format(l, t))\n",
    "            print()\n",
    "            if group == 'TRAIN':\n",
    "                argB_segments.append([tokens[i-3],tokens[i-2],tokens[i-1], 'Arg-B'])\n",
    "#                 mle_train_segments.append([tokens[i-3],tokens[i-2],tokens[i-1], 'Arg-B'])\n",
    "                vocab.append(t)\n",
    "        \n",
    "        # for Arg-I and O tokens\n",
    "        elif group == 'TRAIN':\n",
    "            other_segments.append(tokens[i-3:i])\n",
    "#             mle_train_segments.append([tokens[i-3],tokens[i-2],tokens[i-1], 'O'])\n",
    "            vocab.append(t)\n",
    "\n",
    "vocab = set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE\n",
    "\n",
    "n = 4\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, argB_segments)\n",
    "\n",
    "model = MLE(n) # Lets train a 3-grams maximum likelihood estimation model.\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "argb_train_scores, other_train_scores = [], []\n",
    "argb_test_scores, other_test_scores = [], []\n",
    "\n",
    "for essay, segments, group in zip(essay_spacy, essays_segments, train_test_split.SET):\n",
    "    tokens, labels = get_labels(essay, segments)\n",
    "    for i, (t, l)  in enumerate(zip(tokens, labels)):\n",
    "        if l == 'Arg-B' and group == 'TRAIN':\n",
    "            argb_train_scores.append(model.score('Arg-B',(tokens[i-3],tokens[i-2],tokens[i-1])))\n",
    "        elif group == 'TRAIN':\n",
    "            other_train_scores.append(model.score('Arg-B',(tokens[i-3],tokens[i-2],tokens[i-1])))\n",
    "        elif l == 'Arg-B':\n",
    "            argb_test_scores.append(model.score('Arg-B',(tokens[i-3],tokens[i-2],tokens[i-1])))\n",
    "        else:\n",
    "            other_test_scores.append(model.score('Arg-B',(tokens[i-3],tokens[i-2],tokens[i-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2617, 114929)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in other_train_scores if s > 0]), len(other_train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 1266)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in argb_test_scores if s > 0]), len(argb_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(604, 28549)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([s for s in other_test_scores if s > 0]), len(other_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = everygrams(mle_train_segments, max_len=3)\n",
    "\n",
    "model = MLE(n) # Lets train a 3-grams maximum likelihood estimation model.\n",
    "model.fit(ngrams, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, padded_sents = padded_everygram_pipeline(4, argB_segments)\n",
    "\n",
    "for ngramlize_sent in train_data:\n",
    "    print(list(ngramlize_sent))\n",
    "    print()\n",
    "print('#############')\n",
    "list(padded_sents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
