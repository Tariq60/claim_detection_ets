{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import copy\n",
    "import json\n",
    "import nltk\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import spacy\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "# from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "model_dir = '/Users/talhindi/miniconda3/lib/python3.7/site-packages/en_core_web_sm/en_core_web_sm-2.1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading essays\n",
    "train_test_split = pd.read_csv('../data/SG2017/train-test-split.csv', sep=';')\n",
    "\n",
    "essays_txt_prg_list = []\n",
    "for file in sorted(glob.glob(\"../data/SG2017/*.txt\")):\n",
    "    essay = open(file).readlines()\n",
    "    essays_txt_prg_list.append(essay)\n",
    "\n",
    "essay_txt_str = []\n",
    "for essay in essays_txt_prg_list:\n",
    "    essay_txt_str.append(''.join(essay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "nlp = spacy.load(model_dir)\n",
    "\n",
    "essay_spacy = []\n",
    "for essay in essay_txt_str:\n",
    "    essay_spacy.append(nlp(essay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting sent_splits for train and test\n",
    "token_id = 0\n",
    "sent_token_ids_train, sent_token_ids_test = [], []\n",
    "\n",
    "for i, (doc, group) in enumerate(zip(essay_spacy, train_test_split.SET)):\n",
    "    \n",
    "    if group == \"TRAIN\":\n",
    "        for sent in doc.sents:\n",
    "            sent_tokens_ids = []\n",
    "            for token in sent:\n",
    "                sent_tokens_ids.append(token_id)\n",
    "                token_id +=1\n",
    "            sent_token_ids_train.append(sent_tokens_ids)\n",
    "    \n",
    "    else:\n",
    "        for sent in doc.sents:\n",
    "            sent_tokens_ids = []\n",
    "            for token in sent:\n",
    "                sent_tokens_ids.append(token_id)\n",
    "                token_id +=1\n",
    "            sent_token_ids_test.append(sent_tokens_ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features_labels(n_examples, sent_token_ids, directory, feature_files, suffix):\n",
    "    features, labels, feature_sets = [], [], []\n",
    "    \n",
    "    for file in feature_files:\n",
    "        feature_sets.append(open(directory + file + suffix, 'r').readlines())\n",
    "    \n",
    "    for fset in feature_sets:\n",
    "        assert len(fset) == n_examples\n",
    "    \n",
    "    sent_id, token_id = 0, 0\n",
    "    sent, sent_labels = [], []\n",
    "    for i in range(n_examples):\n",
    "        \n",
    "        token_features = {}\n",
    "        for fset in feature_sets:\n",
    "            jsonline = json.loads(fset[i])\n",
    "            for key in jsonline['x'].keys():\n",
    "                if type(jsonline['x'][key]) is int:\n",
    "                    token_features[key] = float(jsonline['x'][key])\n",
    "                else:\n",
    "                    token_features[key] = jsonline['x'][key]\n",
    "        \n",
    "#         print(sent_id, token_id, sent_token_ids[sent_id][token_id], jsonline['id'])\n",
    "        assert sent_token_ids[sent_id][token_id] == jsonline['id']\n",
    "        \n",
    "        sent.append(copy.deepcopy(token_features))\n",
    "        sent_labels.append(str(jsonline['y']))\n",
    "        del token_features\n",
    "        \n",
    "        if token_id == len(sent_token_ids[sent_id])-1:\n",
    "#             print(jsonline['id'], len(sent), len(sent_labels), len(sent_token_ids[sent_id]))\n",
    "            assert len(sent) == len(sent_labels) == len(sent_token_ids[sent_id])\n",
    "            \n",
    "            features.append(sent)\n",
    "            labels.append(sent_labels)\n",
    "            \n",
    "            sent, sent_labels = [], []\n",
    "            sent_id += 1; token_id = 0\n",
    "        else:\n",
    "            token_id += 1\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_test = 119752, 29815\n",
    "\n",
    "def run_crf_expriments(features, suffix='.jsonlines',\n",
    "                   train_test_sent_splits = [sent_token_ids_train, sent_token_ids_test],\n",
    "                   train_test_directories = ['../features/SG2017_train/', '../features/SG2017_test/'],\n",
    "                   n_train_test = [n_train, n_test]):\n",
    "    \n",
    "    X_train, y_train = read_features_labels(n_train_test[0], train_test_sent_splits[0],\n",
    "                                            train_test_directories[0], features, suffix)\n",
    "    X_test, y_test = read_features_labels(n_train_test[1], train_test_sent_splits[1],\n",
    "                                            train_test_directories[1], features, suffix)\n",
    "    \n",
    "    print('train dir: ', train_test_directories[0])\n",
    "    print('test dir: ', train_test_directories[1])\n",
    "    print('\\nReading the following features: ')\n",
    "    print(features)\n",
    "    \n",
    "    print('\\nBuilding  CRF model')\n",
    "    crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    "    )\n",
    "    print(crf)\n",
    "    \n",
    "    print('\\nTraining Model...')\n",
    "    crf.fit(X_train, y_train)\n",
    "    \n",
    "    print('\\nPredictions on the test set')\n",
    "    y_pred = crf.predict(X_test)\n",
    "    print('Macro F1: ', metrics.flat_f1_score(y_test, y_pred, average='macro', labels=['0.0','1.0','2.0']))\n",
    "    \n",
    "    print('\\nclassification report:')\n",
    "    y_test_flat = [y for y_seq in y_test for y in y_seq]\n",
    "    y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "    print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['position', 'punc', 'position_sent']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.7379007614294025\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.813     0.642     0.718      9801\n",
      "         1.0      0.642     0.598     0.619      1266\n",
      "         2.0      0.832     0.927     0.877     18748\n",
      "\n",
      "    accuracy                          0.820     29815\n",
      "   macro avg      0.762     0.723     0.738     29815\n",
      "weighted avg      0.818     0.820     0.814     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# structural features\n",
    "run_crf_expriments(['position', 'punc', 'position_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['POS', 'LCA_bin', 'LCA_type']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.6747796409086603\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.630     0.623     0.627      9801\n",
      "         1.0      0.638     0.535     0.582      1266\n",
      "         2.0      0.809     0.823     0.816     18748\n",
      "\n",
      "    accuracy                          0.745     29815\n",
      "   macro avg      0.692     0.660     0.675     29815\n",
      "weighted avg      0.743     0.745     0.744     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# syntactic features\n",
    "run_crf_expriments(['POS', 'LCA_bin', 'LCA_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['position', 'punc', 'position_sent', 'POS', 'LCA_bin', 'LCA_type']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.7601211693498886\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.743     0.741     0.742      9801\n",
      "         1.0      0.707     0.635     0.669      1266\n",
      "         2.0      0.866     0.873     0.870     18748\n",
      "\n",
      "    accuracy                          0.820     29815\n",
      "   macro avg      0.772     0.750     0.760     29815\n",
      "weighted avg      0.819     0.820     0.819     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# structural + syntactic features\n",
    "run_crf_expriments(['position', 'punc', 'position_sent', 'POS', 'LCA_bin', 'LCA_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['LexSyn']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.7063305796204723\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.751     0.588     0.659      9801\n",
      "         1.0      0.622     0.588     0.605      1266\n",
      "         2.0      0.810     0.905     0.855     18748\n",
      "\n",
      "    accuracy                          0.787     29815\n",
      "   macro avg      0.728     0.694     0.706     29815\n",
      "weighted avg      0.782     0.787     0.780     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lexsyn... mistake.. only dep relation, no lexical info\n",
    "run_crf_expriments(['LexSyn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['LexSyn_1hop']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.7168117709637286\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.760     0.587     0.662      9801\n",
      "         1.0      0.644     0.619     0.631      1266\n",
      "         2.0      0.810     0.909     0.857     18748\n",
      "\n",
      "    accuracy                          0.791     29815\n",
      "   macro avg      0.738     0.705     0.717     29815\n",
      "weighted avg      0.787     0.791     0.783     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lexsyn 1hop, same as above, sanity check... hmmm, slightly better!\n",
    "run_crf_expriments(['LexSyn_1hop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['LexSyn_1hop']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.7971826180542054\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.795     0.698     0.743      9801\n",
      "         1.0      0.763     0.768     0.765      1266\n",
      "         2.0      0.857     0.911     0.883     18748\n",
      "\n",
      "    accuracy                          0.835     29815\n",
      "   macro avg      0.805     0.792     0.797     29815\n",
      "weighted avg      0.832     0.835     0.832     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lexsyn 1hop, with word\n",
    "run_crf_expriments(['LexSyn_1hop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['LexSyn_2hops']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.7886071128590383\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.772     0.692     0.730      9801\n",
      "         1.0      0.759     0.762     0.761      1266\n",
      "         2.0      0.853     0.899     0.875     18748\n",
      "\n",
      "    accuracy                          0.825     29815\n",
      "   macro avg      0.795     0.784     0.789     29815\n",
      "weighted avg      0.822     0.825     0.823     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lexsyn 2hops, with word\n",
    "\n",
    "run_crf_expriments(['LexSyn_2hops'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['position', 'punc', 'position_sent', 'POS', 'LCA_bin', 'LCA_type', 'LexSyn_1hop']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.8183587608396903\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.777     0.790     0.783      9801\n",
      "         1.0      0.806     0.758     0.781      1266\n",
      "         2.0      0.893     0.889     0.891     18748\n",
      "\n",
      "    accuracy                          0.851     29815\n",
      "   macro avg      0.825     0.812     0.818     29815\n",
      "weighted avg      0.851     0.851     0.851     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_crf_expriments(['position', 'punc', 'position_sent', 'POS', 'LCA_bin', 'LCA_type','LexSyn_1hop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['position', 'punc', 'position_sent', 'LexSyn_1hop']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.8186417498379485\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.788     0.773     0.780      9801\n",
      "         1.0      0.810     0.759     0.784      1266\n",
      "         2.0      0.886     0.898     0.892     18748\n",
      "\n",
      "    accuracy                          0.851     29815\n",
      "   macro avg      0.828     0.810     0.819     29815\n",
      "weighted avg      0.850     0.851     0.851     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_crf_expriments(['position', 'punc', 'position_sent','LexSyn_1hop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dir:  ../features/SG2017_train/\n",
      "test dir:  ../features/SG2017_test/\n",
      "\n",
      "Reading the following features: \n",
      "['POS', 'LCA_bin', 'LCA_type', 'LexSyn_1hop']\n",
      "\n",
      "Building  CRF model\n",
      "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
      "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
      "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
      "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
      "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
      "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
      "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Predictions on the test set\n",
      "Macro F1:  0.7989099608292016\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.796     0.698     0.744      9801\n",
      "         1.0      0.769     0.769     0.769      1266\n",
      "         2.0      0.857     0.912     0.884     18748\n",
      "\n",
      "    accuracy                          0.836     29815\n",
      "   macro avg      0.807     0.793     0.799     29815\n",
      "weighted avg      0.833     0.836     0.833     29815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_crf_expriments(['POS', 'LCA_bin', 'LCA_type','LexSyn_1hop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
