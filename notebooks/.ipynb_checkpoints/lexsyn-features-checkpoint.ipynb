{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import string\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "import networkx as nx\n",
    "model_dir = '/Users/talhindi/miniconda3/lib/python3.7/site-packages/en_core_web_sm/en_core_web_sm-2.1.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = pd.read_csv('../data/SG2017/train-test-split.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_txt_prg_list = []\n",
    "for file in sorted(glob.glob(\"../data/SG2017/*.txt\")):\n",
    "    essay = open(file).readlines()\n",
    "    essays_txt_prg_list.append(essay)\n",
    "\n",
    "essay_txt_str = []\n",
    "for essay in essays_txt_prg_list:\n",
    "    essay_txt_str.append(''.join(essay))\n",
    "    \n",
    "essays_ann = []\n",
    "for file in sorted(glob.glob(\"../data/SG2017/*.ann\")):\n",
    "    essay = open(file).readlines()\n",
    "    essays_ann.append(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_segments = []\n",
    "\n",
    "for essay in essays_ann:    \n",
    "    segments = []\n",
    "    \n",
    "    for line in essay:\n",
    "        if line[0] == 'T':\n",
    "            _, label_s_e, text = line.rstrip().split('\\t')\n",
    "            label, start, end = label_s_e.split()\n",
    "            segments.append((label, int(start), int(end), text))\n",
    "            \n",
    "    segments.sort(key = lambda element : element[1])\n",
    "    essays_segments.append(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(essay_spacy, segments):\n",
    "    '''O = 0, Arg-B = 1, Arg-I = 2'''\n",
    "    \n",
    "    doc_len = len(essay_spacy)\n",
    "    \n",
    "    labels = []\n",
    "    tokens = []\n",
    "    arg_seg_starts = [start for arg_type, start, end, text in segments]\n",
    "    \n",
    "    for token in essay_spacy:\n",
    "        arg_I_token = False\n",
    "\n",
    "        if token.idx in arg_seg_starts:\n",
    "#             labels.append('Arg-B')\n",
    "            labels.append(1.0)\n",
    "            tokens.append(token.text)\n",
    "            assert token.text in segments[arg_seg_starts.index(token.idx)][-1]\n",
    "        else:\n",
    "            for _, start, end, _ in segments:\n",
    "                if token.idx > start and token.idx+len(token) <= end:\n",
    "#                     labels.append('Arg-I')\n",
    "                    labels.append(2.0)\n",
    "                    tokens.append(token.text)\n",
    "                    arg_I_token = True\n",
    "            if not arg_I_token:\n",
    "#                 labels.append('O')\n",
    "                labels.append(0.0)\n",
    "                tokens.append(token.text)\n",
    "\n",
    "    assert len(labels) == doc_len\n",
    "    return tokens, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(model_dir)\n",
    "\n",
    "essay_spacy = []\n",
    "for essay in essay_txt_str:\n",
    "    essay_spacy.append(nlp(essay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(int, {'O': 39617, 'Arg-B': 4823, 'Arg-I': 75312}),\n",
       " defaultdict(int, {'O': 9801, 'Arg-B': 1266, 'Arg-I': 18748}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting labels from each type\n",
    "# without new lines\n",
    "token_labels = []\n",
    "train_BIO = defaultdict(int)\n",
    "test_BIO = defaultdict(int)\n",
    "\n",
    "for doc, segments, group in zip(essay_spacy, essays_segments, train_test_split.SET):\n",
    "    tokens, labels = get_labels(doc, segments)\n",
    "    \n",
    "    if group == \"TRAIN\":\n",
    "        for label in  labels:\n",
    "            train_BIO[label] += 1\n",
    "    else:\n",
    "        for label in  labels:\n",
    "            test_BIO[label] += 1\n",
    "    \n",
    "train_BIO,test_BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LexSyn Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LexSyn 1:\n",
    "        We use lexical head projection rules (Collins 2003) implemented in the Stanford tool suite\n",
    "        to lexicalize the constituent parse tree. \n",
    "        For each token t, we extract its uppermost node n in the parse tree \n",
    "        with the lexical head t and define a lexico- syntactic feature as \n",
    "        the combination of t and the constituent type of n.'''\n",
    "\n",
    "def get_lex_dep_token_context(doc, hops=1):\n",
    "    '''A modification of SG2017 LexSyn features. We get the relation governing the token and its previous and\n",
    "    next tokens. We also go N hops deep in retrieving those relations where N(hops) is a input to this function'''\n",
    "    features = []\n",
    "    for sent in doc.sents:\n",
    "        for i, token in enumerate(sent):\n",
    "            token_features = {}\n",
    "            this_token = token\n",
    "            prev_token = sent[i-1] if i > 0 else 'NO_TOKEN' \n",
    "            next_token = sent[i+1] if i < len(sent)-1 else 'NO_TOKEN'\n",
    "            \n",
    "#             print(this_token, prev_token, next_token)\n",
    "            \n",
    "            for j in range(hops):\n",
    "#                 print(j)\n",
    "                if type(this_token) is not str:\n",
    "                    token_features['dep_{}_{}'.format(j, this_token.dep_)] = 1.0\n",
    "                    token_features['token_dep_{}_{}_{}'.format(j, this_token.dep_, this_token)] = 1.0\n",
    "                    this_token = token.head if this_token.dep_ != 'ROOT' else 'NO_TOKEN'\n",
    "                \n",
    "                if type(prev_token) is not str:\n",
    "                    get_lex_dep_token_prev(sent[i-1], token_features, j)\n",
    "                    prev_token = token.head if prev_token.dep_ != 'ROOT' else 'NO_TOKEN'\n",
    "                \n",
    "                if type(next_token) is not str:\n",
    "                    get_lex_dep_token_next(sent[i+1], token_features, j)\n",
    "                    next_token = token.head if next_token.dep_ != 'ROOT' else 'NO_TOKEN'\n",
    "\n",
    "            features.append(copy.deepcopy(token_features))\n",
    "            del token_features\n",
    "    return features\n",
    "\n",
    "def get_lex_dep_token_prev(prev_token, token_features, j):\n",
    "    token_features['prev_dep_{}_{}'.format(j, prev_token.dep_)] = 1.0\n",
    "    token_features['prev_token_dep_{}_{}_{}'.format(j,prev_token.dep_, prev_token)] = 1.0\n",
    "\n",
    "def get_lex_dep_token_next(next_token, token_features, j):\n",
    "    token_features['next_dep_{}_{}'.format(j, next_token.dep_)] = 1.0\n",
    "    token_features['next_token_dep_{}_{}_{}'.format(j, next_token.dep_, next_token)] = 1.0\n",
    "            \n",
    "\n",
    "'''LexSyn 2:\n",
    "        We also consider the child node of n in the path to t and its right sibling, \n",
    "        and combine their lexical heads and constituent types as described by Soricut and Marcu (2003).'''\n",
    "def get_sibling_features(doc):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexSyn features, 1 hop\n",
    "\n",
    "token_id = 0\n",
    "open('../features/SG2017_train/LexSyn_1hop.jsonlines', 'w')\n",
    "open('../features/SG2017_test/LexSyn_1hop.jsonlines', 'w')\n",
    "\n",
    "for i, (doc, segments, group) in enumerate(zip(essay_spacy, essays_segments, train_test_split.SET)):\n",
    "#     print('essay: ', i)\n",
    "    features = get_lex_dep_token_context(doc)\n",
    "    tokens, labels = get_labels(doc, segments)\n",
    "    \n",
    "    if group == \"TRAIN\":\n",
    "        with open('../features/SG2017_train/LexSyn_1hop.jsonlines', 'a') as file:\n",
    "            for f, l in zip(features, labels):\n",
    "                file.write('{{\"y\": {}, \"x\": {}, \"id\": {}}}\\n'.format(l, json.dumps(f), token_id))\n",
    "                token_id +=1\n",
    "    else:\n",
    "        with open('../features/SG2017_test/LexSyn_1hop.jsonlines', 'a') as file:\n",
    "            for f, l in zip(features, labels):\n",
    "                file.write('{{\"y\": {}, \"x\": {}, \"id\": {}}}\\n'.format(l, json.dumps(f), token_id))\n",
    "                token_id +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexSyn features, 2 hops\n",
    "\n",
    "token_id = 0\n",
    "open('../features/SG2017_train/LexSyn_2hops.jsonlines', 'w')\n",
    "open('../features/SG2017_test/LexSyn_2hops.jsonlines', 'w')\n",
    "\n",
    "for i, (doc, segments, group) in enumerate(zip(essay_spacy, essays_segments, train_test_split.SET)):\n",
    "#     print('essay: ', i)\n",
    "    features = get_lex_dep_token_context(doc, 2)\n",
    "    tokens, labels = get_labels(doc, segments)\n",
    "    \n",
    "    if group == \"TRAIN\":\n",
    "        with open('../features/SG2017_train/LexSyn_2hops.jsonlines', 'a') as file:\n",
    "            for f, l in zip(features, labels):\n",
    "                file.write('{{\"y\": {}, \"x\": {}, \"id\": {}}}\\n'.format(l, json.dumps(f), token_id))\n",
    "                token_id +=1\n",
    "    else:\n",
    "        with open('../features/SG2017_test/LexSyn_2hops.jsonlines', 'a') as file:\n",
    "            for f, l in zip(features, labels):\n",
    "                file.write('{{\"y\": {}, \"x\": {}, \"id\": {}}}\\n'.format(l, json.dumps(f), token_id))\n",
    "                token_id +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "argB_dep, other_dep = [], []\n",
    "for i, (doc, segments, group) in enumerate(zip(essay_spacy, essays_segments, train_test_split.SET)):\n",
    "    if group == \"TRAIN\":\n",
    "        tokens, labels = get_labels(doc, segments)\n",
    "        assert len(doc) == len(labels)\n",
    "        for token, label in zip(doc, labels):\n",
    "            if label == 1.0:\n",
    "                argB_dep.append(token.dep_)\n",
    "            elif label == 2.0:\n",
    "                other_dep.append(token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nsubj', 1821),\n",
       " ('det', 840),\n",
       " ('amod', 426),\n",
       " ('prep', 367),\n",
       " ('advmod', 259),\n",
       " ('csubj', 233),\n",
       " ('mark', 196),\n",
       " ('compound', 128),\n",
       " ('expl', 123),\n",
       " ('nsubjpass', 115),\n",
       " ('poss', 66),\n",
       " ('advcl', 46),\n",
       " ('ROOT', 30),\n",
       " ('cc', 26),\n",
       " ('aux', 22),\n",
       " ('neg', 18),\n",
       " ('pobj', 18),\n",
       " ('npadvmod', 17),\n",
       " ('preconj', 14),\n",
       " ('subtok', 7),\n",
       " ('predet', 7),\n",
       " ('nmod', 6),\n",
       " ('nummod', 5),\n",
       " ('csubjpass', 4),\n",
       " ('pcomp', 4),\n",
       " ('appos', 4),\n",
       " ('dobj', 3),\n",
       " ('punct', 3),\n",
       " ('intj', 3),\n",
       " ('conj', 3),\n",
       " ('dep', 2),\n",
       " ('attr', 2),\n",
       " ('auxpass', 2),\n",
       " ('xcomp', 1),\n",
       " ('acl', 1),\n",
       " ('ccomp', 1)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(argB_dep).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('punct', 11743),\n",
       " ('prep', 11451),\n",
       " ('pobj', 11094),\n",
       " ('det', 7891),\n",
       " ('amod', 7726),\n",
       " ('nsubj', 7230),\n",
       " ('dobj', 6585),\n",
       " ('aux', 6263),\n",
       " ('advmod', 6102),\n",
       " ('ROOT', 5609),\n",
       " ('conj', 4105),\n",
       " ('cc', 3741),\n",
       " ('poss', 2405),\n",
       " ('mark', 2175),\n",
       " ('compound', 2080),\n",
       " ('ccomp', 2024),\n",
       " ('advcl', 2008),\n",
       " ('acomp', 1667),\n",
       " ('xcomp', 1586),\n",
       " ('', 1549),\n",
       " ('relcl', 1352),\n",
       " ('attr', 1222),\n",
       " ('auxpass', 1108),\n",
       " ('pcomp', 1040),\n",
       " ('neg', 849),\n",
       " ('nsubjpass', 814),\n",
       " ('acl', 729),\n",
       " ('case', 397),\n",
       " ('npadvmod', 316),\n",
       " ('prt', 302),\n",
       " ('nummod', 268),\n",
       " ('agent', 215),\n",
       " ('dative', 209),\n",
       " ('expl', 197),\n",
       " ('appos', 187),\n",
       " ('nmod', 136),\n",
       " ('csubj', 124),\n",
       " ('preconj', 110),\n",
       " ('subtok', 86),\n",
       " ('predet', 69),\n",
       " ('oprd', 68),\n",
       " ('dep', 39),\n",
       " ('quantmod', 29),\n",
       " ('parataxis', 11),\n",
       " ('intj', 9),\n",
       " ('csubjpass', 9)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(other_dep).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should/MD <--aux-- taught/VBN <--ROOT--\n",
      "students/NNS <--nsubjpass-- taught/VBN <--ROOT--\n",
      "be/VB <--auxpass-- taught/VBN <--ROOT--\n",
      "taught/VBN <--ROOT-- taught/VBN <--ROOT--\n",
      "to/TO <--aux-- compete/VB <--xcomp--\n",
      "compete/VB <--xcomp-- taught/VBN <--ROOT--\n",
      "or/CC <--cc-- compete/VB <--xcomp--\n",
      "to/TO <--aux-- cooperate/VB <--conj--\n",
      "cooperate/VB <--conj-- compete/VB <--xcomp--\n",
      "?/. <--punct-- taught/VBN <--ROOT--\n",
      "\n",
      "\n",
      "/_SP <---- ?/. <--punct--\n",
      "It/PRP <--nsubjpass-- said/VBN <--ROOT--\n",
      "is/VBZ <--auxpass-- said/VBN <--ROOT--\n",
      "always/RB <--advmod-- said/VBN <--ROOT--\n",
      "said/VBN <--ROOT-- said/VBN <--ROOT--\n",
      "that/IN <--mark-- promote/VB <--ccomp--\n",
      "competition/NN <--nsubj-- promote/VB <--ccomp--\n",
      "can/MD <--aux-- promote/VB <--ccomp--\n",
      "effectively/RB <--advmod-- promote/VB <--ccomp--\n",
      "promote/VB <--ccomp-- said/VBN <--ROOT--\n",
      "the/DT <--det-- development/NN <--dobj--\n",
      "development/NN <--dobj-- promote/VB <--ccomp--\n",
      "of/IN <--prep-- development/NN <--dobj--\n",
      "economy/NN <--pobj-- of/IN <--prep--\n",
      "./. <--punct-- said/VBN <--ROOT--\n",
      "In/IN <--prep-- continue/VBP <--ROOT--\n",
      "order/NN <--pobj-- In/IN <--prep--\n",
      "to/TO <--aux-- survive/VB <--acl--\n",
      "survive/VB <--acl-- order/NN <--pobj--\n",
      "in/IN <--prep-- survive/VB <--acl--\n",
      "the/DT <--det-- competition/NN <--pobj--\n",
      "competition/NN <--pobj-- in/IN <--prep--\n",
      ",/, <--punct-- continue/VBP <--ROOT--\n",
      "companies/NNS <--nsubj-- continue/VBP <--ROOT--\n",
      "continue/VBP <--ROOT-- continue/VBP <--ROOT--\n",
      "to/TO <--aux-- improve/VB <--xcomp--\n",
      "improve/VB <--xcomp-- continue/VBP <--ROOT--\n",
      "their/PRP$ <--poss-- products/NNS <--dobj--\n",
      "products/NNS <--dobj-- improve/VB <--xcomp--\n",
      "and/CC <--cc-- products/NNS <--dobj--\n",
      "service/NN <--conj-- products/NNS <--dobj--\n",
      ",/, <--punct-- improve/VB <--xcomp--\n",
      "and/CC <--cc-- continue/VBP <--ROOT--\n",
      "as/IN <--conj-- continue/VBP <--ROOT--\n",
      "a/DT <--det-- result/NN <--pobj--\n",
      "result/NN <--pobj-- as/IN <--conj--\n",
      ",/, <--punct-- as/IN <--conj--\n",
      "the/DT <--det-- prospers/NNS <--pobj--\n",
      "whole/JJ <--amod-- society/NN <--compound--\n",
      "society/NN <--compound-- prospers/NNS <--pobj--\n",
      "prospers/NNS <--pobj-- as/IN <--conj--\n",
      "./. <--punct-- continue/VBP <--ROOT--\n",
      "However/RB <--advmod-- is/VBZ <--ROOT--\n",
      ",/, <--punct-- is/VBZ <--ROOT--\n",
      "when/WRB <--advmod-- discuss/VBP <--advcl--\n",
      "we/PRP <--nsubj-- discuss/VBP <--advcl--\n",
      "discuss/VBP <--advcl-- is/VBZ <--ROOT--\n",
      "the/DT <--det-- issue/NN <--dobj--\n",
      "issue/NN <--dobj-- discuss/VBP <--advcl--\n",
      "of/IN <--prep-- issue/NN <--dobj--\n",
      "competition/NN <--pobj-- of/IN <--prep--\n",
      "or/CC <--cc-- competition/NN <--pobj--\n",
      "cooperation/NN <--conj-- competition/NN <--pobj--\n",
      ",/, <--punct-- is/VBZ <--ROOT--\n",
      "what/WP <--pobj-- about/IN <--prep--\n",
      "we/PRP <--nsubj-- are/VBP <--csubj--\n",
      "are/VBP <--csubj-- is/VBZ <--ROOT--\n",
      "concerned/JJ <--acomp-- are/VBP <--csubj--\n",
      "about/IN <--prep-- concerned/JJ <--acomp--\n",
      "is/VBZ <--ROOT-- is/VBZ <--ROOT--\n",
      "not/RB <--neg-- is/VBZ <--ROOT--\n",
      "the/DT <--det-- society/NN <--attr--\n",
      "whole/JJ <--amod-- society/NN <--attr--\n",
      "society/NN <--attr-- is/VBZ <--ROOT--\n",
      ",/, <--punct-- is/VBZ <--ROOT--\n",
      "but/CC <--cc-- is/VBZ <--ROOT--\n",
      "the/DT <--det-- development/NN <--conj--\n",
      "development/NN <--conj-- is/VBZ <--ROOT--\n",
      "of/IN <--prep-- development/NN <--conj--\n",
      "an/DT <--det-- individual/NN <--poss--\n",
      "individual/NN <--poss-- life/NN <--pobj--\n",
      "'s/POS <--case-- individual/NN <--poss--\n",
      "whole/JJ <--amod-- life/NN <--pobj--\n",
      "life/NN <--pobj-- of/IN <--prep--\n",
      "./. <--punct-- is/VBZ <--ROOT--\n",
      "From/IN <--prep-- believe/VBP <--ROOT--\n",
      "this/DT <--det-- point/NN <--pobj--\n",
      "point/NN <--pobj-- From/IN <--prep--\n",
      "of/IN <--prep-- point/NN <--pobj--\n",
      "view/NN <--pobj-- of/IN <--prep--\n",
      ",/, <--punct-- believe/VBP <--ROOT--\n",
      "I/PRP <--nsubj-- believe/VBP <--ROOT--\n",
      "firmly/RB <--advmod-- believe/VBP <--ROOT--\n",
      "believe/VBP <--ROOT-- believe/VBP <--ROOT--\n",
      "that/IN <--mark-- attach/VB <--ccomp--\n",
      "we/PRP <--nsubj-- attach/VB <--ccomp--\n",
      "should/MD <--aux-- attach/VB <--ccomp--\n",
      "attach/VB <--ccomp-- believe/VBP <--ROOT--\n",
      "more/JJR <--amod-- importance/NN <--dobj--\n",
      "importance/NN <--dobj-- attach/VB <--ccomp--\n",
      "to/IN <--prep-- attach/VB <--ccomp--\n",
      "cooperation/NN <--pobj-- to/IN <--prep--\n",
      "during/IN <--prep-- cooperation/NN <--pobj--\n",
      "primary/JJ <--amod-- education/NN <--pobj--\n",
      "education/NN <--pobj-- during/IN <--prep--\n",
      "./. <--punct-- believe/VBP <--ROOT--\n",
      "\n",
      "/_SP <---- ./. <--punct--\n",
      "First/RB <--nsubj-- learn/VB <--ROOT--\n",
      "of/IN <--prep-- First/RB <--nsubj--\n",
      "all/DT <--pobj-- of/IN <--prep--\n",
      ",/, <--punct-- learn/VB <--ROOT--\n",
      "through/IN <--prep-- learn/VB <--ROOT--\n",
      "cooperation/NN <--pobj-- through/IN <--prep--\n",
      ",/, <--punct-- learn/VB <--ROOT--\n",
      "children/NNS <--nsubj-- learn/VB <--ROOT--\n",
      "can/MD <--aux-- learn/VB <--ROOT--\n",
      "learn/VB <--ROOT-- learn/VB <--ROOT--\n",
      "about/IN <--prep-- learn/VB <--ROOT--\n",
      "interpersonal/JJ <--amod-- skills/NNS <--pobj--\n",
      "skills/NNS <--pobj-- about/IN <--prep--\n",
      "which/WDT <--nsubj-- are/VBP <--relcl--\n",
      "are/VBP <--relcl-- skills/NNS <--pobj--\n",
      "significant/JJ <--acomp-- are/VBP <--relcl--\n",
      "in/IN <--prep-- significant/JJ <--acomp--\n",
      "the/DT <--det-- life/NN <--pobj--\n",
      "future/JJ <--amod-- life/NN <--pobj--\n",
      "life/NN <--pobj-- in/IN <--prep--\n",
      "of/IN <--prep-- life/NN <--pobj--\n",
      "all/DT <--det-- students/NNS <--pobj--\n",
      "students/NNS <--pobj-- of/IN <--prep--\n",
      "./. <--punct-- learn/VB <--ROOT--\n",
      "What/WP <--dobj-- acquired/VBD <--csubj--\n",
      "we/PRP <--nsubj-- acquired/VBD <--csubj--\n",
      "acquired/VBD <--csubj-- is/VBZ <--ROOT--\n",
      "from/IN <--prep-- acquired/VBD <--csubj--\n",
      "team/NN <--compound-- work/NN <--pobj--\n",
      "work/NN <--pobj-- from/IN <--prep--\n",
      "is/VBZ <--ROOT-- is/VBZ <--ROOT--\n",
      "not/RB <--neg-- is/VBZ <--ROOT--\n",
      "only/RB <--advmod-- not/RB <--neg--\n",
      "how/WRB <--advmod-- achieve/VB <--xcomp--\n",
      "to/TO <--aux-- achieve/VB <--xcomp--\n",
      "achieve/VB <--xcomp-- is/VBZ <--ROOT--\n",
      "the/DT <--det-- goal/NN <--dobj--\n",
      "same/JJ <--amod-- goal/NN <--dobj--\n",
      "goal/NN <--dobj-- achieve/VB <--xcomp--\n",
      "with/IN <--prep-- goal/NN <--dobj--\n",
      "others/NNS <--pobj-- with/IN <--prep--\n",
      "but/CC <--cc-- achieve/VB <--xcomp--\n",
      "more/RBR <--advmod-- importantly/RB <--advmod--\n",
      "importantly/RB <--advmod-- achieve/VB <--xcomp--\n",
      ",/, <--punct-- achieve/VB <--xcomp--\n",
      "how/WRB <--advmod-- get/VB <--conj--\n",
      "to/TO <--aux-- get/VB <--conj--\n",
      "get/VB <--conj-- achieve/VB <--xcomp--\n",
      "along/RP <--prt-- get/VB <--conj--\n",
      "with/IN <--prep-- along/RP <--prt--\n",
      "others/NNS <--pobj-- with/IN <--prep--\n",
      "./. <--punct-- is/VBZ <--ROOT--\n",
      "During/IN <--prep-- learn/VB <--ROOT--\n",
      "the/DT <--det-- process/NN <--pobj--\n",
      "process/NN <--pobj-- During/IN <--prep--\n",
      "of/IN <--prep-- process/NN <--pobj--\n",
      "cooperation/NN <--pobj-- of/IN <--prep--\n",
      ",/, <--punct-- learn/VB <--ROOT--\n",
      "children/NNS <--nsubj-- learn/VB <--ROOT--\n",
      "can/MD <--aux-- learn/VB <--ROOT--\n",
      "learn/VB <--ROOT-- learn/VB <--ROOT--\n",
      "about/IN <--prep-- learn/VB <--ROOT--\n",
      "how/WRB <--advmod-- listen/VB <--pcomp--\n",
      "to/TO <--aux-- listen/VB <--pcomp--\n",
      "listen/VB <--pcomp-- about/IN <--prep--\n",
      "to/IN <--prep-- listen/VB <--pcomp--\n",
      "opinions/NNS <--pobj-- to/IN <--prep--\n",
      "of/IN <--prep-- opinions/NNS <--pobj--\n",
      "others/NNS <--pobj-- of/IN <--prep--\n",
      ",/, <--punct-- listen/VB <--pcomp--\n",
      "how/WRB <--advmod-- communicate/VB <--conj--\n",
      "to/TO <--aux-- communicate/VB <--conj--\n",
      "communicate/VB <--conj-- listen/VB <--pcomp--\n",
      "with/IN <--prep-- communicate/VB <--conj--\n",
      "others/NNS <--pobj-- with/IN <--prep--\n",
      ",/, <--punct-- communicate/VB <--conj--\n",
      "how/WRB <--advmod-- think/VB <--conj--\n",
      "to/TO <--aux-- think/VB <--conj--\n",
      "think/VB <--conj-- communicate/VB <--conj--\n",
      "comprehensively/RB <--advmod-- think/VB <--conj--\n",
      ",/, <--punct-- think/VB <--conj--\n",
      "and/CC <--cc-- think/VB <--conj--\n",
      "even/RB <--advmod-- how/WRB <--advmod--\n",
      "how/WRB <--advmod-- compromise/VB <--conj--\n",
      "to/TO <--aux-- compromise/VB <--conj--\n",
      "compromise/VB <--conj-- think/VB <--conj--\n",
      "with/IN <--prep-- compromise/VB <--conj--\n",
      "other/JJ <--amod-- members/NNS <--pobj--\n",
      "team/NN <--compound-- members/NNS <--pobj--\n",
      "members/NNS <--pobj-- with/IN <--prep--\n",
      "when/WRB <--advmod-- occurred/VBD <--advcl--\n",
      "conflicts/NNS <--nsubj-- occurred/VBD <--advcl--\n",
      "occurred/VBD <--advcl-- compromise/VB <--conj--\n",
      "./. <--punct-- learn/VB <--ROOT--\n",
      "All/DT <--nsubj-- help/VBP <--ROOT--\n",
      "of/IN <--prep-- All/DT <--nsubj--\n",
      "these/DT <--det-- skills/NNS <--pobj--\n",
      "skills/NNS <--pobj-- of/IN <--prep--\n",
      "help/VBP <--ROOT-- help/VBP <--ROOT--\n",
      "them/PRP <--nsubj-- get/VB <--ccomp--\n",
      "to/TO <--aux-- get/VB <--ccomp--\n",
      "get/VB <--ccomp-- help/VBP <--ROOT--\n",
      "on/RP <--prt-- get/VB <--ccomp--\n",
      "well/RB <--advmod-- get/VB <--ccomp--\n",
      "with/IN <--prep-- get/VB <--ccomp--\n",
      "other/JJ <--amod-- people/NNS <--pobj--\n",
      "people/NNS <--pobj-- with/IN <--prep--\n",
      "and/CC <--cc-- help/VBP <--ROOT--\n",
      "will/MD <--aux-- benefit/VB <--conj--\n",
      "benefit/VB <--conj-- help/VBP <--ROOT--\n",
      "them/PRP <--dobj-- benefit/VB <--conj--\n",
      "for/IN <--prep-- benefit/VB <--conj--\n",
      "the/DT <--det-- life/NN <--pobj--\n",
      "whole/JJ <--amod-- life/NN <--pobj--\n",
      "life/NN <--pobj-- for/IN <--prep--\n",
      "./. <--punct-- help/VBP <--ROOT--\n",
      "\n",
      "/_SP <---- ./. <--punct--\n",
      "On/IN <--prep-- is/VBZ <--ROOT--\n",
      "the/DT <--det-- hand/NN <--pobj--\n",
      "other/JJ <--amod-- hand/NN <--pobj--\n",
      "hand/NN <--pobj-- On/IN <--prep--\n",
      ",/, <--punct-- is/VBZ <--ROOT--\n",
      "the/DT <--det-- significance/NN <--nsubj--\n",
      "significance/NN <--nsubj-- is/VBZ <--ROOT--\n",
      "of/IN <--prep-- significance/NN <--nsubj--\n",
      "competition/NN <--pobj-- of/IN <--prep--\n",
      "is/VBZ <--ROOT-- is/VBZ <--ROOT--\n",
      "that/IN <--mark-- become/VB <--ccomp--\n",
      "how/WRB <--advmod-- become/VB <--ccomp--\n",
      "to/TO <--aux-- become/VB <--ccomp--\n",
      "become/VB <--ccomp-- is/VBZ <--ROOT--\n",
      "more/JJR <--amod-- excellence/NN <--attr--\n",
      "excellence/NN <--attr-- become/VB <--ccomp--\n",
      "to/TO <--aux-- gain/VB <--relcl--\n",
      "gain/VB <--relcl-- excellence/NN <--attr--\n",
      "the/DT <--det-- victory/NN <--dobj--\n",
      "victory/NN <--dobj-- gain/VB <--relcl--\n",
      "./. <--punct-- is/VBZ <--ROOT--\n",
      "Hence/RB <--advmod-- said/VBN <--ROOT--\n",
      "it/PRP <--nsubjpass-- said/VBN <--ROOT--\n",
      "is/VBZ <--auxpass-- said/VBN <--ROOT--\n",
      "always/RB <--advmod-- said/VBN <--ROOT--\n",
      "said/VBN <--ROOT-- said/VBN <--ROOT--\n",
      "that/IN <--mark-- makes/VBZ <--ccomp--\n",
      "competition/NN <--nsubj-- makes/VBZ <--ccomp--\n",
      "makes/VBZ <--ccomp-- said/VBN <--ROOT--\n",
      "the/DT <--det-- society/NN <--nsubj--\n",
      "society/NN <--nsubj-- effective/JJ <--ccomp--\n",
      "more/RBR <--advmod-- effective/JJ <--ccomp--\n",
      "effective/JJ <--ccomp-- makes/VBZ <--ccomp--\n",
      "./. <--punct-- said/VBN <--ROOT--\n",
      "However/RB <--ROOT-- However/RB <--ROOT--\n",
      ",/, <--punct-- However/RB <--ROOT--\n",
      "when/WRB <--advmod-- consider/VBP <--advcl--\n",
      "we/PRP <--nsubj-- consider/VBP <--advcl--\n",
      "consider/VBP <--advcl-- However/RB <--ROOT--\n",
      "about/IN <--prep-- consider/VBP <--advcl--\n",
      "the/DT <--det-- question/NN <--pobj--\n",
      "question/NN <--pobj-- about/IN <--prep--\n",
      "that/IN <--mark-- find/VBP <--acl--\n",
      "how/WRB <--advmod-- win/VB <--advcl--\n",
      "to/TO <--aux-- win/VB <--advcl--\n",
      "win/VB <--advcl-- find/VBP <--acl--\n",
      "the/DT <--det-- game/NN <--dobj--\n",
      "game/NN <--dobj-- win/VB <--advcl--\n",
      ",/, <--punct-- find/VBP <--acl--\n",
      "we/PRP <--nsubj-- find/VBP <--acl--\n",
      "always/RB <--advmod-- find/VBP <--acl--\n",
      "find/VBP <--acl-- question/NN <--pobj--\n",
      "that/IN <--mark-- need/VBP <--ccomp--\n",
      "we/PRP <--nsubj-- need/VBP <--ccomp--\n",
      "need/VBP <--ccomp-- find/VBP <--acl--\n",
      "the/DT <--det-- cooperation/NN <--dobj--\n",
      "cooperation/NN <--dobj-- need/VBP <--ccomp--\n",
      "./. <--punct-- However/RB <--ROOT--\n",
      "The/DT <--det-- goal/NN <--nsubj--\n",
      "greater/JJR <--amod-- goal/NN <--nsubj--\n",
      "our/PRP$ <--poss-- goal/NN <--nsubj--\n",
      "goal/NN <--nsubj-- is/VBZ <--ROOT--\n",
      "is/VBZ <--ROOT-- is/VBZ <--ROOT--\n",
      ",/, <--punct-- need/VBP <--ccomp--\n",
      "the/DT <--det-- competition/NN <--dobj--\n",
      "more/JJR <--amod-- competition/NN <--dobj--\n",
      "competition/NN <--dobj-- need/VBP <--ccomp--\n",
      "we/PRP <--nsubj-- need/VBP <--ccomp--\n",
      "need/VBP <--ccomp-- is/VBZ <--ROOT--\n",
      "./. <--punct-- need/VBP <--ccomp--\n",
      "Take/VB <--advcl-- is/VBZ <--ROOT--\n",
      "Olympic/JJ <--amod-- games/NNS <--dobj--\n",
      "games/NNS <--dobj-- Take/VB <--advcl--\n",
      "which/WDT <--nsubj-- is/VBZ <--relcl--\n",
      "is/VBZ <--relcl-- games/NNS <--dobj--\n",
      "a/DT <--det-- form/NN <--attr--\n",
      "form/NN <--attr-- is/VBZ <--relcl--\n",
      "of/IN <--prep-- form/NN <--attr--\n",
      "competition/NN <--pobj-- of/IN <--prep--\n",
      "for/IN <--prep-- competition/NN <--pobj--\n",
      "instance/NN <--pobj-- for/IN <--prep--\n",
      ",/, <--punct-- is/VBZ <--ROOT--\n",
      "it/PRP <--nsubj-- is/VBZ <--ROOT--\n",
      "is/VBZ <--ROOT-- is/VBZ <--ROOT--\n",
      "hard/JJ <--acomp-- is/VBZ <--ROOT--\n",
      "to/TO <--aux-- imagine/VB <--xcomp--\n",
      "imagine/VB <--xcomp-- is/VBZ <--ROOT--\n",
      "how/WRB <--advmod-- win/VB <--ccomp--\n",
      "an/DT <--det-- athlete/NN <--nsubj--\n",
      "athlete/NN <--nsubj-- win/VB <--ccomp--\n",
      "could/MD <--aux-- win/VB <--ccomp--\n",
      "win/VB <--ccomp-- imagine/VB <--xcomp--\n",
      "the/DT <--det-- game/NN <--dobj--\n",
      "game/NN <--dobj-- win/VB <--ccomp--\n",
      "without/IN <--prep-- win/VB <--ccomp--\n",
      "the/DT <--det-- training/NN <--pobj--\n",
      "training/NN <--pobj-- without/IN <--prep--\n",
      "of/IN <--prep-- training/NN <--pobj--\n",
      "his/PRP$ <--poss-- coach/NN <--pobj--\n",
      "or/CC <--cc-- his/PRP$ <--poss--\n",
      "her/PRP$ <--poss-- coach/NN <--pobj--\n",
      "coach/NN <--pobj-- of/IN <--prep--\n",
      ",/, <--punct-- is/VBZ <--ROOT--\n",
      "and/CC <--cc-- is/VBZ <--ROOT--\n",
      "the/DT <--det-- help/NN <--conj--\n",
      "help/NN <--conj-- is/VBZ <--ROOT--\n",
      "of/IN <--prep-- help/NN <--conj--\n",
      "other/JJ <--amod-- staffs/NNS <--pobj--\n",
      "professional/JJ <--amod-- staffs/NNS <--pobj--\n",
      "staffs/NNS <--pobj-- of/IN <--prep--\n",
      "such/JJ <--amod-- as/IN <--prep--\n",
      "as/IN <--prep-- staffs/NNS <--pobj--\n",
      "the/DT <--det-- people/NNS <--pobj--\n",
      "people/NNS <--pobj-- as/IN <--prep--\n",
      "who/WP <--nsubj-- take/VBP <--relcl--\n",
      "take/VBP <--relcl-- people/NNS <--pobj--\n",
      "care/NN <--dobj-- take/VBP <--relcl--\n",
      "of/IN <--prep-- take/VBP <--relcl--\n",
      "his/PRP$ <--poss-- diet/NN <--pobj--\n",
      "diet/NN <--pobj-- of/IN <--prep--\n",
      ",/, <--punct-- help/NN <--conj--\n",
      "and/CC <--cc-- help/NN <--conj--\n",
      "those/DT <--conj-- help/NN <--conj--\n",
      "who/WP <--nsubj-- are/VBP <--relcl--\n",
      "are/VBP <--relcl-- those/DT <--conj--\n",
      "in/IN <--prep-- are/VBP <--relcl--\n",
      "charge/NN <--pobj-- in/IN <--prep--\n",
      "of/IN <--prep-- charge/NN <--pobj--\n",
      "the/DT <--det-- care/NN <--pobj--\n",
      "medical/JJ <--amod-- care/NN <--pobj--\n",
      "care/NN <--pobj-- of/IN <--prep--\n",
      "./. <--punct-- is/VBZ <--ROOT--\n",
      "The/DT <--det-- winner/NN <--nsubj--\n",
      "winner/NN <--nsubj-- is/VBZ <--ROOT--\n",
      "is/VBZ <--ROOT-- is/VBZ <--ROOT--\n",
      "the/DT <--det-- athlete/NN <--attr--\n",
      "athlete/NN <--attr-- is/VBZ <--ROOT--\n",
      "but/CC <--cc-- is/VBZ <--ROOT--\n",
      "the/DT <--det-- success/NN <--nsubj--\n",
      "success/NN <--nsubj-- belongs/VBZ <--conj--\n",
      "belongs/VBZ <--conj-- is/VBZ <--ROOT--\n",
      "to/IN <--prep-- belongs/VBZ <--conj--\n",
      "the/DT <--det-- team/NN <--pobj--\n",
      "whole/JJ <--amod-- team/NN <--pobj--\n",
      "team/NN <--pobj-- to/IN <--prep--\n",
      "./. <--punct-- belongs/VBZ <--conj--\n",
      "Therefore/RB <--advmod-- be/VB <--ROOT--\n",
      "without/IN <--prep-- be/VB <--ROOT--\n",
      "the/DT <--det-- cooperation/NN <--pobj--\n",
      "cooperation/NN <--pobj-- without/IN <--prep--\n",
      ",/, <--punct-- be/VB <--ROOT--\n",
      "there/EX <--expl-- be/VB <--ROOT--\n",
      "would/MD <--aux-- be/VB <--ROOT--\n",
      "be/VB <--ROOT-- be/VB <--ROOT--\n",
      "no/DT <--det-- victory/NN <--attr--\n",
      "victory/NN <--attr-- be/VB <--ROOT--\n",
      "of/IN <--prep-- victory/NN <--attr--\n",
      "competition/NN <--pobj-- of/IN <--prep--\n",
      "./. <--punct-- be/VB <--ROOT--\n",
      "\n",
      "/_SP <---- ./. <--punct--\n",
      "Consequently/RB <--advmod-- receive/VB <--ROOT--\n",
      ",/, <--punct-- receive/VB <--ROOT--\n",
      "no/RB <--neg-- matter/NN <--advmod--\n",
      "matter/NN <--advmod-- receive/VB <--ROOT--\n",
      "from/IN <--prep-- matter/NN <--advmod--\n",
      "the/DT <--det-- view/NN <--pobj--\n",
      "view/NN <--pobj-- from/IN <--prep--\n",
      "of/IN <--prep-- view/NN <--pobj--\n",
      "individual/JJ <--amod-- development/NN <--pobj--\n",
      "development/NN <--pobj-- of/IN <--prep--\n",
      "or/CC <--cc-- development/NN <--pobj--\n",
      "the/DT <--det-- relationship/NN <--conj--\n",
      "relationship/NN <--conj-- development/NN <--pobj--\n",
      "between/IN <--prep-- relationship/NN <--conj--\n",
      "competition/NN <--pobj-- between/IN <--prep--\n",
      "and/CC <--cc-- competition/NN <--pobj--\n",
      "cooperation/NN <--conj-- competition/NN <--pobj--\n",
      "we/PRP <--nsubj-- receive/VB <--ROOT--\n",
      "can/MD <--aux-- receive/VB <--ROOT--\n",
      "receive/VB <--ROOT-- receive/VB <--ROOT--\n",
      "the/DT <--det-- conclusion/NN <--dobj--\n",
      "same/JJ <--amod-- conclusion/NN <--dobj--\n",
      "conclusion/NN <--dobj-- receive/VB <--ROOT--\n",
      "that/IN <--mark-- is/VBZ <--acl--\n",
      "a/DT <--det-- attitudes/NNS <--nsubj--\n",
      "more/RBR <--advmod-- cooperative/JJ <--amod--\n",
      "cooperative/JJ <--amod-- attitudes/NNS <--nsubj--\n",
      "attitudes/NNS <--nsubj-- is/VBZ <--acl--\n",
      "towards/IN <--prep-- attitudes/NNS <--nsubj--\n",
      "life/NN <--pobj-- towards/IN <--prep--\n",
      "is/VBZ <--acl-- conclusion/NN <--dobj--\n",
      "more/RBR <--advmod-- profitable/JJ <--acomp--\n",
      "profitable/JJ <--acomp-- is/VBZ <--acl--\n",
      "in/IN <--prep-- is/VBZ <--acl--\n",
      "one/PRP <--poss-- success/NN <--pobj--\n",
      "'s/POS <--case-- one/PRP <--poss--\n",
      "success/NN <--pobj-- in/IN <--prep--\n",
      "./. <--punct-- receive/VB <--ROOT--\n"
     ]
    }
   ],
   "source": [
    "for sent in essay_spacy[0].sents:\n",
    "    for token in sent:\n",
    "        print(\"{0}/{1} <--{2}-- {3}/{4} <--{5}--\".format(token.text, token.tag_, token.dep_, token.head.text, token.head.tag_,\n",
    "                                           token.head.dep_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hop only\n",
    "'''LexSyn 1:\n",
    "        We use lexical head projection rules (Collins 2003) implemented in the Stanford tool suite\n",
    "        to lexicalize the constituent parse tree. \n",
    "        For each token t, we extract its uppermost node n in the parse tree \n",
    "        with the lexical head t and define a lexico- syntactic feature as \n",
    "        the combination of t and the constituent type of n.'''\n",
    "\n",
    "def get_lex_dep_token_context(doc, hops=1):\n",
    "    '''A modification of SG2017 LexSyn features. We get the relation governing the token and its previous and\n",
    "    next tokens. We also go N hops deep in retrieving those relations where N(hops) is a input to this function'''\n",
    "    features = []\n",
    "    for sent in doc.sents:\n",
    "        for i, token in enumerate(sent):\n",
    "            token_features = {}\n",
    "            token_features['dep_{}'.format(token.dep_)] = 1.0\n",
    "            token_features['token_dep_{}'.format(token.dep_)] = 1.0\n",
    "            if i == 0:\n",
    "                get_lex_dep_token_next(sent[i+1], token_features)\n",
    "            elif i == len(sent)-1:\n",
    "                get_lex_dep_token_prev(sent[i-1], token_features)\n",
    "            else:\n",
    "                get_lex_dep_token_prev(sent[i-1], token_features)\n",
    "                get_lex_dep_token_next(sent[i+1], token_features)\n",
    "            \n",
    "            features.append(copy.deepcopy(token_features))\n",
    "            del token_features\n",
    "    return features\n",
    "\n",
    "def get_lex_dep_token_prev(prev_token, token_features):\n",
    "    token_features['prev_dep_{}'.format(prev_token.dep_)] = 1.0\n",
    "    token_features['prev_token_dep_{}'.format(prev_token.dep_)] = 1.0\n",
    "\n",
    "def get_lex_dep_token_next(next_token, token_features):\n",
    "    token_features['next_dep_{}'.format(next_token.dep_)] = 1.0\n",
    "    token_features['next_token_dep_{}'.format(next_token.dep_)] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sdp_path(doc, subj, obj, lca_matrix):\n",
    "    lca = lca_matrix[subj, obj]\n",
    "  \n",
    "    current_node = doc[subj]\n",
    "    subj_path = [current_node]\n",
    "    if lca != -1: \n",
    "        if lca != subj: \n",
    "            while current_node.head.i != lca:\n",
    "                current_node = current_node.head\n",
    "                subj_path.append(current_node)\n",
    "            subj_path.append(current_node.head)\n",
    "            \n",
    "    current_node = doc[obj]\n",
    "    obj_path = [current_node]\n",
    "    if lca != -1: \n",
    "        if lca != obj: \n",
    "            while current_node.head.i != lca:\n",
    "                current_node = current_node.head\n",
    "                obj_path.append(current_node)\n",
    "            obj_path.append(current_node.head)\n",
    "  \n",
    "    return subj_path + obj_path[::-1][1:]\n",
    "  \n",
    "\n",
    "nlp = spacy.load(model_dir)\n",
    "doc = nlp(u'Convulsions that occur after DTaP are caused by a fever, and fever may cause headache.')\n",
    "# set head entity index and tail entity index\n",
    "head, tail = 0, 9\n",
    "\n",
    "sdp = get_sdp_path(doc, head, tail, doc.get_lca_matrix())\n",
    "print(sdp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
