{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "# from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_labels(token_list):\n",
    "    sent_labels, sentences, sent_start = [], [], 0\n",
    "    for i, line in enumerate(token_list):\n",
    "        if line == '\\n':\n",
    "            sentences.append(sent_labels)\n",
    "            sent_labels = []\n",
    "        else:        \n",
    "            token, label = line.rstrip().split()\n",
    "            sent_labels.append(label)\n",
    "    return sentences\n",
    "\n",
    "def sent2features(sent_emb):\n",
    "    features = []\n",
    "\n",
    "    for word_emb in sent_emb:\n",
    "        word_features = {}\n",
    "        if len(word_emb.shape) > 0:\n",
    "            for i in range(word_emb.shape[0]):\n",
    "                word_features['bert_features_{}'.format(i)] = float(word_emb[i])\n",
    "        else:\n",
    "            word_features['bert_features_0'] = float(word_emb)\n",
    "            \n",
    "        features.append(copy.deepcopy(word_features))\n",
    "        del word_features\n",
    "    \n",
    "    return features\n",
    "\n",
    "def merge_features(bert_features, other_features):\n",
    "    \n",
    "    for sent_emb_features, sent_other_features in zip(bert_features, other_features):\n",
    "        \n",
    "        for word_emb_features, word_other_features in zip(sent_emb_features[:len(sent_other_features)], sent_other_features):\n",
    "            word_other_features.update(word_emb_features)\n",
    "        \n",
    "        if len(sent_other_features) > len(sent_emb_features):\n",
    "            for _ in range(len(sent_other_features)-len(sent_emb_features)):\n",
    "                sent_other_features.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266 1266\n",
      "1862 1862\n",
      "1332 1332\n"
     ]
    }
   ],
   "source": [
    "wm1 = open('../../data_wm/arg_clean_45_1/test.txt','r').readlines()\n",
    "wm1_labels = get_sent_labels(wm1)\n",
    "wm1_features = pickle.load(open('../features/wm1_emb.p','rb'))\n",
    "print(len(wm1_features), len(wm1_labels))\n",
    "\n",
    "wm2 = open('../../data_wm/arg_clean_45_2/train.txt','r').readlines()\n",
    "wm2_labels = get_sent_labels(wm2)\n",
    "wm2_features = pickle.load(open('../features/wm2_emb.p','rb'))\n",
    "print(len(wm2_features), len(wm2_labels))\n",
    "\n",
    "wm_nr = open('../../data_wm/wm_narrative/test.txt','r').readlines()\n",
    "wm_nr_labels = get_sent_labels(wm_nr)\n",
    "\n",
    "wm_nr_features = pickle.load(open('../features/wm_nr_emb.p','rb'))\n",
    "print(len(wm_nr_features), len(wm_nr_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm1_lexsyn = pickle.load(open('../features/wm1_lexsyn.p','rb'))\n",
    "wm2_lexsyn = pickle.load(open('../features/wm2_lexsyn.p','rb'))\n",
    "wm_nr_lexsyn = pickle.load(open('../features/wm_nr_lexsyn.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm1_all = pickle.load(open('../features/wm1_all.p','rb'))\n",
    "wm2_all = pickle.load(open('../features/wm2_all.p','rb'))\n",
    "wm_nr_all = pickle.load(open('../features/wm_nr_all.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, max1, max2 = 0, 800, 300\n",
    "wm2_features, wm2_lexsyn, wm2_all, wm2_labels = shuffle(wm2_features, wm2_lexsyn, wm2_all, wm2_labels, random_state=0)\n",
    "\n",
    "wm2_features_ds,  wm2_lexsyn_ds,  wm2_all_ds,  wm2_labels_ds  = [], [], [], []\n",
    "wm2_features_ds2, wm2_lexsyn_ds2, wm2_all_ds2, wm2_labels_ds2 = [], [], [], []\n",
    "\n",
    "for bert, lexsyn, _all, labels in zip(wm2_features, wm2_lexsyn, wm2_all, wm2_labels):\n",
    "    \n",
    "    if all([label == 'O-claim' for label in labels]):\n",
    "        \n",
    "        if count < max1:\n",
    "            wm2_features_ds.append(bert)\n",
    "            wm2_lexsyn_ds.append(lexsyn)\n",
    "            wm2_all_ds.append(_all)\n",
    "            wm2_labels_ds.append(labels)\n",
    "            \n",
    "            if count < max2:\n",
    "                wm2_features_ds2.append(bert)\n",
    "                wm2_lexsyn_ds2.append(lexsyn)\n",
    "                wm2_all_ds2.append(_all)\n",
    "                wm2_labels_ds2.append(labels)\n",
    "        \n",
    "        count += 1\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        wm2_features_ds.append(bert)\n",
    "        wm2_lexsyn_ds.append(lexsyn)\n",
    "        wm2_all_ds.append(_all)\n",
    "        wm2_labels_ds.append(labels)\n",
    "        \n",
    "        wm2_features_ds2.append(bert)\n",
    "        wm2_lexsyn_ds2.append(lexsyn)\n",
    "        wm2_all_ds2.append(_all)\n",
    "        wm2_labels_ds2.append(labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'O-claim': 10909, 'B-claim': 951, 'I-claim': 10263}),\n",
       " Counter({'O-claim': 20326, 'B-claim': 951, 'I-claim': 10263}),\n",
       " Counter({'O-claim': 25332, 'B-claim': 951, 'I-claim': 10263}))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([label for labels in wm2_labels_ds2 for label in labels]), \\\n",
    "Counter([label for labels in wm2_labels_ds for label in labels]), \\\n",
    "Counter([label for labels in wm2_labels for label in labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.487     0.321     0.387       707\n",
      "     I-claim      0.623     0.485     0.546      7407\n",
      "     O-claim      0.778     0.865     0.819     16841\n",
      "\n",
      "    accuracy                          0.737     24955\n",
      "   macro avg      0.630     0.557     0.584     24955\n",
      "weighted avg      0.724     0.737     0.726     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.040     0.297     0.071        37\n",
      "     I-claim      0.070     0.509     0.123       350\n",
      "     O-claim      0.990     0.878     0.931     21465\n",
      "\n",
      "    accuracy                          0.871     21852\n",
      "   macro avg      0.367     0.561     0.375     21852\n",
      "weighted avg      0.974     0.871     0.916     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bert embeddings only\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_features_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(wm1_features)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_features)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.483     0.199     0.282       707\n",
      "     I-claim      0.714     0.261     0.383      7407\n",
      "     O-claim      0.730     0.951     0.826     16841\n",
      "\n",
      "    accuracy                          0.725     24955\n",
      "   macro avg      0.642     0.471     0.497     24955\n",
      "weighted avg      0.718     0.725     0.679     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.065     0.189     0.097        37\n",
      "     I-claim      0.119     0.237     0.158       350\n",
      "     O-claim      0.986     0.967     0.976     21465\n",
      "\n",
      "    accuracy                          0.954     21852\n",
      "   macro avg      0.390     0.464     0.411     21852\n",
      "weighted avg      0.971     0.954     0.962     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bert embeddings only\n",
    "crf = sklearn_crfsuite.CRF(algorithm='l2sgd', c2=0.1, max_iterations=1000, all_possible_transitions=True)\n",
    "crf.fit(wm2_features_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(wm1_features)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_features)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.348     0.504     0.411       707\n",
      "     I-claim      0.453     0.850     0.591      7407\n",
      "     O-claim      0.883     0.525     0.659     16841\n",
      "\n",
      "    accuracy                          0.621     24955\n",
      "   macro avg      0.561     0.626     0.554     24955\n",
      "weighted avg      0.740     0.621     0.631     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.018     0.459     0.035        37\n",
      "     I-claim      0.036     0.934     0.070       350\n",
      "     O-claim      0.998     0.556     0.714     21465\n",
      "\n",
      "    accuracy                          0.562     21852\n",
      "   macro avg      0.351     0.650     0.273     21852\n",
      "weighted avg      0.981     0.562     0.702     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bert embeddings only\n",
    "crf = sklearn_crfsuite.CRF(algorithm='l2sgd', c2=0.1, max_iterations=1000, all_possible_transitions=True)\n",
    "crf.fit(wm2_features_ds2, wm2_labels_ds2)\n",
    "\n",
    "y_pred = crf.predict(wm1_features)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_features)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LexSyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.544     0.338     0.417       707\n",
      "     I-claim      0.650     0.458     0.537      7407\n",
      "     O-claim      0.774     0.886     0.826     16841\n",
      "\n",
      "    accuracy                          0.744     24955\n",
      "   macro avg      0.656     0.561     0.593     24955\n",
      "weighted avg      0.730     0.744     0.729     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.044     0.270     0.075        37\n",
      "     I-claim      0.068     0.469     0.119       350\n",
      "     O-claim      0.989     0.886     0.935     21465\n",
      "\n",
      "    accuracy                          0.878     21852\n",
      "   macro avg      0.367     0.542     0.376     21852\n",
      "weighted avg      0.973     0.878     0.920     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='l2sgd', c2=0.1, max_iterations=1000, all_possible_transitions=True)\n",
    "crf.fit(wm2_lexsyn_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(wm1_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.449     0.482     0.465       707\n",
      "     I-claim      0.538     0.644     0.586      7407\n",
      "     O-claim      0.815     0.741     0.776     16841\n",
      "\n",
      "    accuracy                          0.705     24955\n",
      "   macro avg      0.600     0.623     0.609     24955\n",
      "weighted avg      0.722     0.705     0.711     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.026     0.378     0.049        37\n",
      "     I-claim      0.042     0.657     0.078       350\n",
      "     O-claim      0.992     0.730     0.841     21465\n",
      "\n",
      "    accuracy                          0.728     21852\n",
      "   macro avg      0.353     0.588     0.323     21852\n",
      "weighted avg      0.975     0.728     0.827     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='l2sgd', c2=0.1, max_iterations=1000, all_possible_transitions=True)\n",
    "crf.fit(wm2_lexsyn_ds2, wm2_labels_ds2)\n",
    "\n",
    "y_pred = crf.predict(wm1_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT + LexSyn features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_lexsyn has both lexsyn and bert features after using merge\n",
    "merge_features(wm1_features, wm1_lexsyn)\n",
    "merge_features(wm2_features_ds, wm2_lexsyn_ds)\n",
    "merge_features(wm2_features_ds2, wm2_lexsyn_ds2)\n",
    "merge_features(wm_nr_features, wm_nr_lexsyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.552     0.396     0.461       707\n",
      "     I-claim      0.681     0.543     0.604      7407\n",
      "     O-claim      0.801     0.882     0.840     16841\n",
      "\n",
      "    accuracy                          0.768     24955\n",
      "   macro avg      0.678     0.607     0.635     24955\n",
      "weighted avg      0.758     0.768     0.759     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.056     0.351     0.096        37\n",
      "     I-claim      0.101     0.591     0.173       350\n",
      "     O-claim      0.992     0.904     0.946     21465\n",
      "\n",
      "    accuracy                          0.898     21852\n",
      "   macro avg      0.383     0.616     0.405     21852\n",
      "weighted avg      0.976     0.898     0.932     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_lexsyn_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(wm1_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.473     0.515     0.493       707\n",
      "     I-claim      0.585     0.683     0.630      7407\n",
      "     O-claim      0.836     0.772     0.803     16841\n",
      "\n",
      "    accuracy                          0.738     24955\n",
      "   macro avg      0.631     0.656     0.642     24955\n",
      "weighted avg      0.751     0.738     0.743     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.031     0.432     0.058        37\n",
      "     I-claim      0.055     0.634     0.101       350\n",
      "     O-claim      0.992     0.799     0.885     21465\n",
      "\n",
      "    accuracy                          0.796     21852\n",
      "   macro avg      0.359     0.622     0.348     21852\n",
      "weighted avg      0.975     0.796     0.871     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_lexsyn_ds2, wm2_labels_ds2)\n",
    "\n",
    "y_pred = crf.predict(wm1_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_lexsyn)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Discrete Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.466     0.392     0.425       707\n",
      "     I-claim      0.570     0.631     0.599      7407\n",
      "     O-claim      0.815     0.782     0.798     16841\n",
      "\n",
      "    accuracy                          0.726     24955\n",
      "   macro avg      0.617     0.602     0.607     24955\n",
      "weighted avg      0.732     0.726     0.728     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.041     0.324     0.073        37\n",
      "     I-claim      0.054     0.526     0.098       350\n",
      "     O-claim      0.990     0.838     0.908     21465\n",
      "\n",
      "    accuracy                          0.832     21852\n",
      "   macro avg      0.362     0.563     0.360     21852\n",
      "weighted avg      0.973     0.832     0.893     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_all_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(wm1_all)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_all)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.473     0.501     0.486       707\n",
      "     I-claim      0.519     0.709     0.599      7407\n",
      "     O-claim      0.833     0.697     0.759     16841\n",
      "\n",
      "    accuracy                          0.695     24955\n",
      "   macro avg      0.608     0.636     0.615     24955\n",
      "weighted avg      0.730     0.695     0.704     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.043     0.270     0.074        37\n",
      "     I-claim      0.061     0.463     0.107       350\n",
      "     O-claim      0.989     0.873     0.927     21465\n",
      "\n",
      "    accuracy                          0.865     21852\n",
      "   macro avg      0.364     0.535     0.369     21852\n",
      "weighted avg      0.973     0.865     0.913     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_all_ds2, wm2_labels_ds2)\n",
    "\n",
    "y_pred = crf.predict(wm1_all)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_all)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Discrete + BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_all has both all and bert features after using merge\n",
    "merge_features(wm1_features, wm1_all)\n",
    "merge_features(wm2_all_ds, wm2_all_ds)\n",
    "merge_features(wm2_all_ds2, wm2_all_ds2)\n",
    "merge_features(wm_nr_features, wm_nr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.466     0.392     0.425       707\n",
      "     I-claim      0.570     0.631     0.599      7407\n",
      "     O-claim      0.815     0.782     0.798     16841\n",
      "\n",
      "    accuracy                          0.726     24955\n",
      "   macro avg      0.617     0.602     0.607     24955\n",
      "weighted avg      0.732     0.726     0.728     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.041     0.324     0.073        37\n",
      "     I-claim      0.054     0.526     0.098       350\n",
      "     O-claim      0.990     0.838     0.908     21465\n",
      "\n",
      "    accuracy                          0.832     21852\n",
      "   macro avg      0.362     0.563     0.360     21852\n",
      "weighted avg      0.973     0.832     0.893     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "# crf = sklearn_crfsuite.CRF(algorithm='l2sgd', c2=0.1, max_iterations=1000, all_possible_transitions=True)\n",
    "crf.fit(wm2_all_ds, wm2_labels_ds)\n",
    "\n",
    "y_pred = crf.predict(wm1_all)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_all)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.473     0.501     0.486       707\n",
      "     I-claim      0.519     0.709     0.599      7407\n",
      "     O-claim      0.833     0.697     0.759     16841\n",
      "\n",
      "    accuracy                          0.695     24955\n",
      "   macro avg      0.608     0.636     0.615     24955\n",
      "weighted avg      0.730     0.695     0.704     24955\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     B-claim      0.043     0.270     0.074        37\n",
      "     I-claim      0.061     0.463     0.107       350\n",
      "     O-claim      0.989     0.873     0.927     21465\n",
      "\n",
      "    accuracy                          0.865     21852\n",
      "   macro avg      0.364     0.535     0.369     21852\n",
      "weighted avg      0.973     0.865     0.913     21852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "crf.fit(wm2_all_ds2, wm2_labels_ds2)\n",
    "\n",
    "y_pred = crf.predict(wm1_all)\n",
    "y_test_flat = [y for y_seq in wm1_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))\n",
    "\n",
    "y_pred = crf.predict(wm_nr_all)\n",
    "y_test_flat = [y for y_seq in wm_nr_labels for y in y_seq]\n",
    "y_pred_flat = [y for y_seq in y_pred for y in y_seq]\n",
    "print(classification_report(y_test_flat, y_pred_flat, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
